# data_extractor.py
import re
from pathlib import Path
import os

# ç›´æ¥å®šä¹‰é…ç½®ï¼Œé¿å…å¯¼å…¥é—®é¢˜
BASE_DIR = Path(__file__).parent
PDF_DIR = BASE_DIR / "arxiv_pdfs"
TEXT_DIR = BASE_DIR / "arxiv_texts"

# åˆ›å»ºç›®å½•
PDF_DIR.mkdir(exist_ok=True)
TEXT_DIR.mkdir(exist_ok=True)

print(f"PDFç›®å½•: {PDF_DIR}")
print(f"æ–‡æœ¬ç›®å½•: {TEXT_DIR}")

try:
    import fitz  # PyMuPDF
    HAS_FITZ = True
    print("âœ“ PyMuPDF å·²å®‰è£…")
except ImportError:
    HAS_FITZ = False
    print("âœ— PyMuPDF æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç¤ºä¾‹æ•°æ®")

def extract_text_from_pdf(pdf_path: Path) -> str:
    """ä»PDFæå–æ–‡æœ¬"""
    try:
        if HAS_FITZ:
            doc = fitz.open(pdf_path)
            text = ""
            for page in doc:
                page_text = page.get_text("text")
                text += page_text + "\n"
            return text.strip()
        else:
            # è¿”å›ç¤ºä¾‹æ–‡æœ¬
            return create_sample_content(pdf_path.stem)
    except Exception as e:
        print(f"ä» {pdf_path} æå–æ–‡æœ¬æ—¶å‡ºé”™: {e}")
        return create_sample_content(pdf_path.stem)

def clean_text(text: str) -> str:
    """æ¸…ç†æ–‡æœ¬"""
    text = re.sub(r"\s+", " ", text)
    return text.strip()

def extract_abstract(text: str) -> str:
    """æå–æ‘˜è¦éƒ¨åˆ†"""
    patterns = [
        r"abstract[:\s]*(.*?)(?=introduction|$)",
        r"Abstract[:\s]*(.*?)(?=Introduction|$)",
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
        if match:
            return match.group(1).strip()
    return text[:300] + "..." if len(text) > 300 else text

def create_sample_content(title: str) -> str:
    """åˆ›å»ºç¤ºä¾‹å†…å®¹"""
    samples = {
        "transformer": """
        Abstract: This paper introduces a novel transformer architecture that improves computational efficiency by 40% while maintaining performance. Our method uses sparse attention mechanisms to reduce quadratic complexity.
        
        Introduction: Transformers have revolutionized NLP but face computational challenges. Recent approaches focus on optimizing attention mechanisms.
        
        Method: We propose a dynamic sparse attention mechanism that selectively attends to relevant tokens based on content-based routing.
        
        Results: Experimental results on GLUE benchmark show 40% faster inference with only 1% accuracy drop compared to dense transformers.
        """,
        "machine_learning": """
        Abstract: We present a comprehensive survey of machine learning techniques, focusing on deep learning architectures and their applications in various domains.
        
        Introduction: Machine learning has evolved rapidly in recent years, with deep learning achieving state-of-the-art results in many tasks.
        
        Deep Learning Architectures: We review CNN, RNN, and transformer architectures, comparing their strengths and limitations.
        
        Applications: Discuss applications in computer vision, natural language processing, and reinforcement learning.
        """,
        "default": """
        Abstract: This research paper presents advancements in AI methodologies, demonstrating improved performance across multiple benchmarks while reducing computational requirements.
        
        Introduction: Recent developments in artificial intelligence have focused on scaling model size and improving training efficiency.
        
        Contributions: Our main contributions include a novel optimization algorithm and improved regularization techniques.
        
        Experiments: We evaluate on standard benchmarks and show consistent improvements over baseline methods.
        """
    }
    
    for key in samples:
        if key in title.lower():
            return samples[key]
    return samples["default"]

def create_sample_pdfs():
    """åˆ›å»ºç¤ºä¾‹PDFæ–‡ä»¶"""
    samples = [
        {"name": "transformer_research.pdf", "content": create_sample_content("transformer")},
        {"name": "ml_survey.pdf", "content": create_sample_content("machine_learning")},
        {"name": "ai_advances.pdf", "content": create_sample_content("default")}
    ]
    
    for sample in samples:
        filepath = PDF_DIR / sample["name"]
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(sample["content"])
        print(f"åˆ›å»ºç¤ºä¾‹æ–‡ä»¶: {filepath}")

def get_paper_data() -> list:
    """è·å–è®ºæ–‡æ•°æ®"""
    papers = []
    pdf_files = list(PDF_DIR.glob("*.pdf"))
    
    if not pdf_files:
        print("æœªæ‰¾åˆ°PDFæ–‡ä»¶ï¼Œåˆ›å»ºç¤ºä¾‹æ–‡ä»¶...")
        create_sample_pdfs()
        pdf_files = list(PDF_DIR.glob("*.pdf"))
    
    print(f"æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
    
    for i, pdf_file in enumerate(pdf_files):
        try:
            print(f"å¤„ç†æ–‡ä»¶ {i+1}/{len(pdf_files)}: {pdf_file.name}")
            text = extract_text_from_pdf(pdf_file)
            abstract = extract_abstract(text)
            
            papers.append({
                "title": pdf_file.stem,
                "abstract": clean_text(abstract),
                "full_text": clean_text(text)[:1000]  # é™åˆ¶æ–‡æœ¬é•¿åº¦
            })
            print(f"âœ“ æˆåŠŸå¤„ç†: {pdf_file.stem}")
            
        except Exception as e:
            print(f"âœ— å¤„ç† {pdf_file} æ—¶å‡ºé”™: {e}")
    
    return papers

def save_paper_texts(papers: list):
    """ä¿å­˜è®ºæ–‡æ–‡æœ¬"""
    for i, paper in enumerate(papers):
        filepath = TEXT_DIR / f"paper_{i+1}.txt"
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(f"Title: {paper['title']}\n")
            f.write(f"Abstract: {paper['abstract']}\n")
            f.write(f"Text: {paper['full_text']}\n")
        print(f"ä¿å­˜: {filepath}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("æ•°æ®æå–æ¨¡å—")
    print("=" * 60)
    
    # è·å–è®ºæ–‡æ•°æ®
    papers = get_paper_data()
    
    if papers:
        # ä¿å­˜æ–‡æœ¬
        save_paper_texts(papers)
        print(f"\nâœ… æˆåŠŸå¤„ç†å¹¶ä¿å­˜ {len(papers)} ç¯‡è®ºæ–‡")
        
        # æ˜¾ç¤ºæ‘˜è¦
        print("\nğŸ“„ è®ºæ–‡æ‘˜è¦:")
        for i, paper in enumerate(papers, 1):
            print(f"{i}. {paper['title']}")
            print(f"   Abstract: {paper['abstract'][:100]}...")
            print()
    else:
        print("âŒ æ²¡æœ‰å¤„ç†ä»»ä½•è®ºæ–‡")

if __name__ == "__main__":
    main()