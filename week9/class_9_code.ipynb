{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Building Your First Voice Agent - Class 9 Interactive Tutorial\n",
    "================================================================\n",
    "This notebook will guide you through creating a complete voice agent from scratch!\n",
    "\n",
    "\n",
    "# ğŸ¯ Building Your First Voice Agent\n",
    " \n",
    "Welcome to an exciting journey into the world of voice technology! In this notebook, you'll learn to build your own voice agent that can:\n",
    "- ğŸ¤ Listen to your voice (Speech Recognition)\n",
    "- ğŸ§  Understand what you're asking\n",
    "- ğŸ—£ï¸ Respond with a voice (Text-to-Speech)\n",
    "\n",
    "By the end of this tutorial, you'll have created your own personal assistant!\n",
    "\n",
    "\n",
    "## ğŸ“š What You'll Learn\n",
    " \n",
    "1. **Speech Recognition (ASR)** - How computers \"hear\" and understand speech\n",
    "2. **Text-to-Speech (TTS)** - How computers can talk back to you\n",
    "3. **Natural Language Processing** - How computers understand meaning\n",
    "4. **Integration** - Putting it all together into a working voice agent\n",
    "\n",
    "Let's start our journey! ğŸš€\n",
    "\n",
    "\n",
    "## ğŸ› ï¸ Step 1: Setting Up Our Tools\n",
    "First, we need to install the libraries that will help us build our voice agent.\n",
    "\n",
    "**What each library does:**\n",
    "- `speech_recognition`: Converts your speech to text (ASR)\n",
    "- `pyttsx3`: Converts text to speech (TTS)\n",
    "- `pyaudio`: Handles audio input/output\n",
    "- `requests`: Gets information from the internet\n",
    "- `datetime`: Works with dates and times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Installing required packages...\n",
      "Requirement already satisfied: speechrecognition in ./w9-env/lib/python3.11/site-packages (3.14.3)\n",
      "Requirement already satisfied: typing-extensions in ./w9-env/lib/python3.11/site-packages (from speechrecognition) (4.15.0)\n",
      "âœ… speechrecognition installed successfully!\n",
      "Requirement already satisfied: pyttsx3 in ./w9-env/lib/python3.11/site-packages (2.99)\n",
      "Requirement already satisfied: pyobjc>=2.4 in ./w9-env/lib/python3.11/site-packages (from pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-core==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-libdispatch==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-libxpc==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Accessibility==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-AdServices==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-AdSupport==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-AppTrackingTransparency==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-AudioVideoBridging==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-AuthenticationServices==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-AutomaticAssessmentConfiguration==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-AVKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-AVFoundation==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-AVRouting==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Accounts==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-AddressBook==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-AppleScriptKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-AppleScriptObjC==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ApplicationServices==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Automator==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-BackgroundAssets==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-BrowserEngineKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-BusinessChat==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CFNetwork==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CalendarStore==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CallKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Carbon==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Cinematic==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ClassKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CloudKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Cocoa==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Collaboration==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ColorSync==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Contacts==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ContactsUI==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CoreAudio==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CoreAudioKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CoreBluetooth==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CoreData==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CoreHaptics==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CoreLocation==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CoreMedia==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CoreMediaIO==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CoreMIDI==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CoreML==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CoreMotion==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CoreServices==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CoreSpotlight==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CoreText==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CoreWLAN==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-CryptoTokenKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-DataDetection==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-DeviceCheck==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-DeviceDiscoveryExtension==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-DictionaryServices==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-DiscRecording==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-DiscRecordingUI==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-DiskArbitration==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-DVDPlayback==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-EventKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ExceptionHandling==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ExecutionPolicy==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ExternalAccessory==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ExtensionKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-FileProvider==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-FileProviderUI==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-FSEvents==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-FSKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-FinderSync==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-GameCenter==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-GameController==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-HealthKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-InputMethodKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ImageCaptureCore==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Intents==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-IntentsUI==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-InstallerPlugins==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-InstantMessage==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-IOBluetooth==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-IOBluetoothUI==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-IOSurface==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-KernelManagement==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-LatentSemanticMapping==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-LaunchServices==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-LinkPresentation==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-LocalAuthentication==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-LocalAuthenticationEmbeddedUI==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-MailKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-MapKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-MediaAccessibility==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-MediaExtension==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-MediaLibrary==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-MediaPlayer==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-MediaToolbox==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Metal==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-MetalFX==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-MetalKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-MetalPerformanceShaders==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-MetalPerformanceShadersGraph==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-MetricKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-MLCompute==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ModelIO==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-MultipeerConnectivity==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-NaturalLanguage==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-NetFS==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Network==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-NetworkExtension==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-NotificationCenter==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-OpenDirectory==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-OSAKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-OSLog==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-PassKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-PencilKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-PHASE==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Photos==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-PhotosUI==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-PreferencePanes==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-PushKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Quartz==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-QuickLookThumbnailing==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ReplayKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-SafetyKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-SafariServices==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ScreenSaver==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ScreenTime==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ScriptingBridge==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Security==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-SecurityFoundation==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-SecurityInterface==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-SecurityUI==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-SearchKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ServiceManagement==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ShazamKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Social==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Speech==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-SpriteKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-StoreKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-SyncServices==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-SystemConfiguration==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-WebKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-GameKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-GameplayKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-SceneKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-SensitiveContentAnalysis==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-SharedWithYouCore==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-SharedWithYou==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-SoundAnalysis==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ScreenCaptureKit==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Symbols==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-SystemExtensions==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-ThreadNetwork==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-UniformTypeIdentifiers==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-UserNotifications==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-UserNotificationsUI==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-VideoSubscriberAccount==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-VideoToolbox==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Virtualization==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-Vision==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "Requirement already satisfied: pyobjc-framework-iTunesLibrary==11.1 in ./w9-env/lib/python3.11/site-packages (from pyobjc>=2.4->pyttsx3) (11.1)\n",
      "âœ… pyttsx3 installed successfully!\n",
      "Requirement already satisfied: pyaudio in ./w9-env/lib/python3.11/site-packages (0.2.14)\n",
      "âœ… pyaudio installed successfully!\n",
      "Requirement already satisfied: requests in ./w9-env/lib/python3.11/site-packages (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./w9-env/lib/python3.11/site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./w9-env/lib/python3.11/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./w9-env/lib/python3.11/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./w9-env/lib/python3.11/site-packages (from requests) (2025.8.3)\n",
      "âœ… requests installed successfully!\n",
      "Requirement already satisfied: wikipedia in ./w9-env/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in ./w9-env/lib/python3.11/site-packages (from wikipedia) (4.13.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in ./w9-env/lib/python3.11/site-packages (from wikipedia) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./w9-env/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./w9-env/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./w9-env/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./w9-env/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.8.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./w9-env/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./w9-env/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (4.15.0)\n",
      "âœ… wikipedia installed successfully!\n",
      "\n",
      "ğŸ‰ All packages installed! Let's start coding!\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries (run this cell first!)\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"âœ… {package} installed successfully!\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"âŒ Failed to install {package}\")\n",
    "\n",
    "# List of packages we need\n",
    "packages = [\n",
    "    \"speechrecognition\",\n",
    "    \"pyttsx3\", \n",
    "    \"pyaudio\",\n",
    "    \"requests\",\n",
    "    \"wikipedia\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ”§ Installing required packages...\")\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\nğŸ‰ All packages installed! Let's start coding!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤ Step 2: Understanding Speech Recognition (ASR)\n",
    "Speech Recognition is like giving your computer ears! Let's see how it works.\n",
    "\n",
    "The Process:\n",
    "\n",
    "1. Your voice creates sound waves\n",
    "\n",
    "2. Microphone converts sound waves to electrical signals\n",
    "\n",
    "3. Computer converts signals to digital data\n",
    "\n",
    "4. AI analyzes the data and finds words\n",
    "\n",
    "5. Returns text that matches your speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! brew install portaudio\n",
    "# ! pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤ Creating Speech Recognizer...\n",
      "\n",
      "ğŸ” Testing microphone...\n",
      "ğŸ“± Found 3 microphones:\n",
      "  0: Levyçš„ iPhone Microphone\n",
      "  1: MacBook Pro Microphone\n",
      "  2: MacBook Pro Speakers\n",
      "ğŸ™ï¸ Microphone is working!\n",
      "ğŸ“Š Adjusting for background noise... (2 seconds)\n",
      "âœ… Microphone setup complete!\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import time\n",
    "\n",
    "# Create our speech recognizer\n",
    "print(\"ğŸ¤ Creating Speech Recognizer...\")\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Let's test if our microphone works\n",
    "def test_microphone():\n",
    "    \"\"\"Test if our microphone is working\"\"\"\n",
    "    print(\"\\nğŸ” Testing microphone...\")\n",
    "    \n",
    "    # Get list of available microphones\n",
    "    mic_list = sr.Microphone.list_microphone_names()\n",
    "    print(f\"ğŸ“± Found {len(mic_list)} microphones:\")\n",
    "    \n",
    "    for i, name in enumerate(mic_list[:3]):  # Show first 3\n",
    "        print(f\"  {i}: {name}\")\n",
    "    \n",
    "    # Test with default microphone\n",
    "    try:\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"ğŸ™ï¸ Microphone is working!\")\n",
    "            print(\"ğŸ“Š Adjusting for background noise... (2 seconds)\")\n",
    "            recognizer.adjust_for_ambient_noise(source, duration=2)\n",
    "            print(\"âœ… Microphone setup complete!\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Microphone error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Test our setup\n",
    "mic_working = test_microphone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª Experiment 1: Your First Speech Recognition\n",
    " \n",
    "Let's try converting your speech to text! This is the foundation of all voice agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¤ EXPERIMENT: Speech to Text\n",
      "========================================\n",
      "ğŸ“¢ Instructions:\n",
      "1. Click 'Run' on this cell\n",
      "2. When you see 'Listening...', start speaking\n",
      "3. Speak clearly for 3-5 seconds\n",
      "4. Watch the magic happen!\n",
      "\n",
      "ğŸ§ Listening... Speak now!\n",
      "(Speak clearly for 3-5 seconds)\n",
      "ğŸ”„ Processing your speech...\n",
      "ğŸ¤” Could not understand the audio. Try speaking more clearly!\n"
     ]
    }
   ],
   "source": [
    "def listen_once():\n",
    "    \"\"\"Listen to user speech and convert to text\"\"\"\n",
    "    if not mic_working:\n",
    "        print(\"âŒ Microphone not working. Please check your setup.\")\n",
    "        return \"microphone not working\"\n",
    "    \n",
    "    print(\"\\nğŸ¤ EXPERIMENT: Speech to Text\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"ğŸ“¢ Instructions:\")\n",
    "    print(\"1. Click 'Run' on this cell\")\n",
    "    print(\"2. When you see 'Listening...', start speaking\")\n",
    "    print(\"3. Speak clearly for 3-5 seconds\")\n",
    "    print(\"4. Watch the magic happen!\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"ğŸ§ Listening... Speak now!\")\n",
    "            print(\"(Speak clearly for 3-5 seconds)\")\n",
    "            \n",
    "            # Listen for audio with timeout\n",
    "            audio = recognizer.listen(source, timeout=10, phrase_time_limit=5)\n",
    "            print(\"ğŸ”„ Processing your speech...\")\n",
    "            \n",
    "            # Convert speech to text using Google's free service\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            \n",
    "            print(f\"\\nâœ¨ SUCCESS! You said: '{text}'\")\n",
    "            print(f\"ğŸ“ Text length: {len(text)} characters\")\n",
    "            return text\n",
    "            \n",
    "    except sr.WaitTimeoutError:\n",
    "        print(\"â° No speech detected. Try speaking louder!\")\n",
    "        return \"\"\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"ğŸ¤” Could not understand the audio. Try speaking more clearly!\")\n",
    "        return \"\"\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"ğŸŒ Internet connection error: {e}\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Unexpected error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Try it now!\n",
    "user_speech = listen_once()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Challenge 1: Test Different Scenarios\n",
    " \n",
    "Let's see how well speech recognition works in different situations!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† SPEECH RECOGNITION CHALLENGE\n",
      "==================================================\n",
      "\n",
      "ğŸ“ Challenge 1: Say a simple word like 'hello'\n",
      "   Get ready to speak in 3 seconds...\n",
      "\n",
      "ğŸ¤ EXPERIMENT: Speech to Text\n",
      "========================================\n",
      "ğŸ“¢ Instructions:\n",
      "1. Click 'Run' on this cell\n",
      "2. When you see 'Listening...', start speaking\n",
      "3. Speak clearly for 3-5 seconds\n",
      "4. Watch the magic happen!\n",
      "\n",
      "ğŸ§ Listening... Speak now!\n",
      "(Speak clearly for 3-5 seconds)\n",
      "ğŸ”„ Processing your speech...\n",
      "ğŸ¤” Could not understand the audio. Try speaking more clearly!\n",
      "\n",
      "ğŸ¤ EXPERIMENT: Speech to Text\n",
      "========================================\n",
      "ğŸ“¢ Instructions:\n",
      "1. Click 'Run' on this cell\n",
      "2. When you see 'Listening...', start speaking\n",
      "3. Speak clearly for 3-5 seconds\n",
      "4. Watch the magic happen!\n",
      "\n",
      "ğŸ§ Listening... Speak now!\n",
      "(Speak clearly for 3-5 seconds)\n",
      "ğŸ”„ Processing your speech...\n",
      "\n",
      "âœ¨ SUCCESS! You said: 'hello'\n",
      "ğŸ“ Text length: 5 characters\n",
      "   âœ… Result: 'hello'\n",
      "------------------------------\n",
      "\n",
      "ğŸ“ Challenge 2: Say a long sentence about your favorite hobby\n",
      "   Get ready to speak in 3 seconds...\n",
      "\n",
      "ğŸ¤ EXPERIMENT: Speech to Text\n",
      "========================================\n",
      "ğŸ“¢ Instructions:\n",
      "1. Click 'Run' on this cell\n",
      "2. When you see 'Listening...', start speaking\n",
      "3. Speak clearly for 3-5 seconds\n",
      "4. Watch the magic happen!\n",
      "\n",
      "ğŸ§ Listening... Speak now!\n",
      "(Speak clearly for 3-5 seconds)\n",
      "ğŸ”„ Processing your speech...\n",
      "ğŸ¤” Could not understand the audio. Try speaking more clearly!\n",
      "\n",
      "ğŸ¤ EXPERIMENT: Speech to Text\n",
      "========================================\n",
      "ğŸ“¢ Instructions:\n",
      "1. Click 'Run' on this cell\n",
      "2. When you see 'Listening...', start speaking\n",
      "3. Speak clearly for 3-5 seconds\n",
      "4. Watch the magic happen!\n",
      "\n",
      "ğŸ§ Listening... Speak now!\n",
      "(Speak clearly for 3-5 seconds)\n",
      "ğŸ”„ Processing your speech...\n",
      "ğŸ¤” Could not understand the audio. Try speaking more clearly!\n",
      "   âŒ No result\n",
      "------------------------------\n",
      "\n",
      "ğŸ“ Challenge 3: Try speaking very quietly\n",
      "   Get ready to speak in 3 seconds...\n",
      "\n",
      "ğŸ¤ EXPERIMENT: Speech to Text\n",
      "========================================\n",
      "ğŸ“¢ Instructions:\n",
      "1. Click 'Run' on this cell\n",
      "2. When you see 'Listening...', start speaking\n",
      "3. Speak clearly for 3-5 seconds\n",
      "4. Watch the magic happen!\n",
      "\n",
      "ğŸ§ Listening... Speak now!\n",
      "(Speak clearly for 3-5 seconds)\n",
      "ğŸ”„ Processing your speech...\n",
      "ğŸ¤” Could not understand the audio. Try speaking more clearly!\n",
      "\n",
      "ğŸ¤ EXPERIMENT: Speech to Text\n",
      "========================================\n",
      "ğŸ“¢ Instructions:\n",
      "1. Click 'Run' on this cell\n",
      "2. When you see 'Listening...', start speaking\n",
      "3. Speak clearly for 3-5 seconds\n",
      "4. Watch the magic happen!\n",
      "\n",
      "ğŸ§ Listening... Speak now!\n",
      "(Speak clearly for 3-5 seconds)\n",
      "ğŸ”„ Processing your speech...\n",
      "ğŸ¤” Could not understand the audio. Try speaking more clearly!\n",
      "   âŒ No result\n",
      "------------------------------\n",
      "\n",
      "ğŸ“ Challenge 4: Try speaking very fast\n",
      "   Get ready to speak in 3 seconds...\n",
      "\n",
      "ğŸ¤ EXPERIMENT: Speech to Text\n",
      "========================================\n",
      "ğŸ“¢ Instructions:\n",
      "1. Click 'Run' on this cell\n",
      "2. When you see 'Listening...', start speaking\n",
      "3. Speak clearly for 3-5 seconds\n",
      "4. Watch the magic happen!\n",
      "\n",
      "ğŸ§ Listening... Speak now!\n",
      "(Speak clearly for 3-5 seconds)\n",
      "â° No speech detected. Try speaking louder!\n",
      "\n",
      "ğŸ¤ EXPERIMENT: Speech to Text\n",
      "========================================\n",
      "ğŸ“¢ Instructions:\n",
      "1. Click 'Run' on this cell\n",
      "2. When you see 'Listening...', start speaking\n",
      "3. Speak clearly for 3-5 seconds\n",
      "4. Watch the magic happen!\n",
      "\n",
      "ğŸ§ Listening... Speak now!\n",
      "(Speak clearly for 3-5 seconds)\n",
      "â° No speech detected. Try speaking louder!\n",
      "   âŒ No result\n",
      "------------------------------\n",
      "\n",
      "ğŸ“ Challenge 5: Say some numbers like 'twelve thirty-four'\n",
      "   Get ready to speak in 3 seconds...\n",
      "\n",
      "ğŸ¤ EXPERIMENT: Speech to Text\n",
      "========================================\n",
      "ğŸ“¢ Instructions:\n",
      "1. Click 'Run' on this cell\n",
      "2. When you see 'Listening...', start speaking\n",
      "3. Speak clearly for 3-5 seconds\n",
      "4. Watch the magic happen!\n",
      "\n",
      "ğŸ§ Listening... Speak now!\n",
      "(Speak clearly for 3-5 seconds)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# run the challenge!\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m challenge_results = \u001b[43mspeech_recognition_challenge\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mspeech_recognition_challenge\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   Get ready to speak in 3 seconds...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m time.sleep(\u001b[32m3\u001b[39m)   \u001b[38;5;66;03m# å€’è®¡æ—¶3ç§’\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m result = \u001b[43mlisten_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m result = listen_once()\n\u001b[32m     26\u001b[39m results.append(result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mlisten_once\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m(Speak clearly for 3-5 seconds)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Listen for audio with timeout\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m audio = \u001b[43mrecognizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphrase_time_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ”„ Processing your speech...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Convert speech to text using Google's free service\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLE_Training/week9/w9-env/lib/python3.11/site-packages/speech_recognition/__init__.py:460\u001b[39m, in \u001b[36mRecognizer.listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    458\u001b[39m result = \u001b[38;5;28mself\u001b[39m._listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLE_Training/week9/w9-env/lib/python3.11/site-packages/speech_recognition/__init__.py:492\u001b[39m, in \u001b[36mRecognizer._listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time > timeout:\n\u001b[32m    490\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[33m\"\u001b[39m\u001b[33mlistening timed out while waiting for phrase to start\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m buffer = \u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) == \u001b[32m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[32m    494\u001b[39m frames.append(buffer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLE_Training/week9/w9-env/lib/python3.11/site-packages/speech_recognition/__init__.py:191\u001b[39m, in \u001b[36mMicrophone.MicrophoneStream.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpyaudio_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLE_Training/week9/w9-env/lib/python3.11/site-packages/pyaudio/__init__.py:570\u001b[39m, in \u001b[36mPyAudio.Stream.read\u001b[39m\u001b[34m(self, num_frames, exception_on_overflow)\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_input:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNot input stream\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    569\u001b[39m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def speech_recognition_challenge():\n",
    "    \"\"\"Test speech recognition with different challenges\"\"\"\n",
    "    print(\"ğŸ† SPEECH RECOGNITION CHALLENGE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    challenges = [\n",
    "        \"Say a simple word like 'hello'\",\n",
    "        \"Say a long sentence about your favorite hobby\",\n",
    "        \"Try speaking very quietly\",\n",
    "        \"Try speaking very fast\",\n",
    "        \"Say some numbers like 'twelve thirty-four'\"\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, challenge in enumerate(challenges, 1):\n",
    "        print(f\"\\nğŸ“ Challenge {i}: {challenge}\")\n",
    "        # input(\"   Press Enter when ready to speak...\")\n",
    "        print(\"   Get ready to speak in 3 seconds...\")\n",
    "        time.sleep(3)   # å€’è®¡æ—¶3ç§’\n",
    "        result = listen_once()\n",
    "\n",
    "        result = listen_once()\n",
    "        results.append(result)\n",
    "        \n",
    "        if result:\n",
    "            print(f\"   âœ… Result: '{result}'\")\n",
    "        else:\n",
    "            print(\"   âŒ No result\")\n",
    "            \n",
    "        print(\"-\" * 30)\n",
    "    \n",
    "    print(\"\\nğŸ“Š CHALLENGE SUMMARY:\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        status = \"âœ… Success\" if result else \"âŒ Failed\"\n",
    "        print(f\"Challenge {i}: {status}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# run the challenge!\n",
    "challenge_results = speech_recognition_challenge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—£ï¸ Step 3: Understanding Text-to-Speech (TTS)\n",
    " \n",
    "Now let's give our computer a voice! Text-to-Speech is like giving your computer a mouth.\n",
    " \n",
    "**The Process:**\n",
    "1. Computer receives text\n",
    "2. AI analyzes the words and grammar\n",
    "3. Determines pronunciation and emphasis\n",
    "4. Generates sound waves that match human speech\n",
    "5. Plays the audio through speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—£ï¸ Setting up Text-to-Speech...\n",
      "\n",
      "ğŸ­ EXPLORING AVAILABLE VOICES\n",
      "========================================\n",
      "ğŸ” Found 177 voices on your system:\n",
      "\n",
      "  Voice 0:\n",
      "    Name: Albert\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Albert\n",
      "\n",
      "  Voice 1:\n",
      "    Name: Alice\n",
      "    Gender: Unknown\n",
      "    Language: it_IT\n",
      "    ID: com.apple.voice.compact.it-IT.Alice\n",
      "\n",
      "  Voice 2:\n",
      "    Name: Alva\n",
      "    Gender: Unknown\n",
      "    Language: sv_SE\n",
      "    ID: com.apple.voice.compact.sv-SE.Alva\n",
      "\n",
      "  Voice 3:\n",
      "    Name: AmÃ©lie\n",
      "    Gender: Unknown\n",
      "    Language: fr_CA\n",
      "    ID: com.apple.voice.compact.fr-CA.Amelie\n",
      "\n",
      "  Voice 4:\n",
      "    Name: Amira\n",
      "    Gender: Unknown\n",
      "    Language: ms_MY\n",
      "    ID: com.apple.voice.compact.ms-MY.Amira\n",
      "\n",
      "  Voice 5:\n",
      "    Name: Anna\n",
      "    Gender: Unknown\n",
      "    Language: de_DE\n",
      "    ID: com.apple.voice.compact.de-DE.Anna\n",
      "\n",
      "  Voice 6:\n",
      "    Name: Bad News\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.BadNews\n",
      "\n",
      "  Voice 7:\n",
      "    Name: Bahh\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Bahh\n",
      "\n",
      "  Voice 8:\n",
      "    Name: Bells\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Bells\n",
      "\n",
      "  Voice 9:\n",
      "    Name: Boing\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Boing\n",
      "\n",
      "  Voice 10:\n",
      "    Name: Bubbles\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Bubbles\n",
      "\n",
      "  Voice 11:\n",
      "    Name: Carmit\n",
      "    Gender: Unknown\n",
      "    Language: he_IL\n",
      "    ID: com.apple.voice.compact.he-IL.Carmit\n",
      "\n",
      "  Voice 12:\n",
      "    Name: Cellos\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Cellos\n",
      "\n",
      "  Voice 13:\n",
      "    Name: Damayanti\n",
      "    Gender: Unknown\n",
      "    Language: id_ID\n",
      "    ID: com.apple.voice.compact.id-ID.Damayanti\n",
      "\n",
      "  Voice 14:\n",
      "    Name: Daniel\n",
      "    Gender: Unknown\n",
      "    Language: en_GB\n",
      "    ID: com.apple.voice.compact.en-GB.Daniel\n",
      "\n",
      "  Voice 15:\n",
      "    Name: Daria\n",
      "    Gender: Unknown\n",
      "    Language: bg_BG\n",
      "    ID: com.apple.voice.compact.bg-BG.Daria\n",
      "\n",
      "  Voice 16:\n",
      "    Name: Wobble\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Deranged\n",
      "\n",
      "  Voice 17:\n",
      "    Name: Eddy (German (Germany))\n",
      "    Gender: Unknown\n",
      "    Language: de_DE\n",
      "    ID: com.apple.eloquence.de-DE.Eddy\n",
      "\n",
      "  Voice 18:\n",
      "    Name: Eddy (English (UK))\n",
      "    Gender: Unknown\n",
      "    Language: en_GB\n",
      "    ID: com.apple.eloquence.en-GB.Eddy\n",
      "\n",
      "  Voice 19:\n",
      "    Name: Eddy (English (US))\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.eloquence.en-US.Eddy\n",
      "\n",
      "  Voice 20:\n",
      "    Name: Eddy (Spanish (Spain))\n",
      "    Gender: Unknown\n",
      "    Language: es_ES\n",
      "    ID: com.apple.eloquence.es-ES.Eddy\n",
      "\n",
      "  Voice 21:\n",
      "    Name: Eddy (Spanish (Mexico))\n",
      "    Gender: Unknown\n",
      "    Language: es_MX\n",
      "    ID: com.apple.eloquence.es-MX.Eddy\n",
      "\n",
      "  Voice 22:\n",
      "    Name: Eddy (Finnish (Finland))\n",
      "    Gender: Unknown\n",
      "    Language: fi_FI\n",
      "    ID: com.apple.eloquence.fi-FI.Eddy\n",
      "\n",
      "  Voice 23:\n",
      "    Name: Eddy (French (Canada))\n",
      "    Gender: Unknown\n",
      "    Language: fr_CA\n",
      "    ID: com.apple.eloquence.fr-CA.Eddy\n",
      "\n",
      "  Voice 24:\n",
      "    Name: Eddy (French (France))\n",
      "    Gender: Unknown\n",
      "    Language: fr_FR\n",
      "    ID: com.apple.eloquence.fr-FR.Eddy\n",
      "\n",
      "  Voice 25:\n",
      "    Name: Eddy (Italian (Italy))\n",
      "    Gender: Unknown\n",
      "    Language: it_IT\n",
      "    ID: com.apple.eloquence.it-IT.Eddy\n",
      "\n",
      "  Voice 26:\n",
      "    Name: Eddy (Japanese (Japan))\n",
      "    Gender: Unknown\n",
      "    Language: ja_JP\n",
      "    ID: com.apple.eloquence.ja-JP.Eddy\n",
      "\n",
      "  Voice 27:\n",
      "    Name: Eddy (Korean (South Korea))\n",
      "    Gender: Unknown\n",
      "    Language: ko_KR\n",
      "    ID: com.apple.eloquence.ko-KR.Eddy\n",
      "\n",
      "  Voice 28:\n",
      "    Name: Eddy (Portuguese (Brazil))\n",
      "    Gender: Unknown\n",
      "    Language: pt_BR\n",
      "    ID: com.apple.eloquence.pt-BR.Eddy\n",
      "\n",
      "  Voice 29:\n",
      "    Name: Eddy (Chinese (China mainland))\n",
      "    Gender: Unknown\n",
      "    Language: zh_CN\n",
      "    ID: com.apple.eloquence.zh-CN.Eddy\n",
      "\n",
      "  Voice 30:\n",
      "    Name: Eddy (Chinese (Taiwan))\n",
      "    Gender: Unknown\n",
      "    Language: zh_TW\n",
      "    ID: com.apple.eloquence.zh-TW.Eddy\n",
      "\n",
      "  Voice 31:\n",
      "    Name: Ellen\n",
      "    Gender: Unknown\n",
      "    Language: nl_BE\n",
      "    ID: com.apple.voice.compact.nl-BE.Ellen\n",
      "\n",
      "  Voice 32:\n",
      "    Name: Flo (German (Germany))\n",
      "    Gender: Unknown\n",
      "    Language: de_DE\n",
      "    ID: com.apple.eloquence.de-DE.Flo\n",
      "\n",
      "  Voice 33:\n",
      "    Name: Flo (English (UK))\n",
      "    Gender: Unknown\n",
      "    Language: en_GB\n",
      "    ID: com.apple.eloquence.en-GB.Flo\n",
      "\n",
      "  Voice 34:\n",
      "    Name: Flo (English (US))\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.eloquence.en-US.Flo\n",
      "\n",
      "  Voice 35:\n",
      "    Name: Flo (Spanish (Spain))\n",
      "    Gender: Unknown\n",
      "    Language: es_ES\n",
      "    ID: com.apple.eloquence.es-ES.Flo\n",
      "\n",
      "  Voice 36:\n",
      "    Name: Flo (Spanish (Mexico))\n",
      "    Gender: Unknown\n",
      "    Language: es_MX\n",
      "    ID: com.apple.eloquence.es-MX.Flo\n",
      "\n",
      "  Voice 37:\n",
      "    Name: Flo (Finnish (Finland))\n",
      "    Gender: Unknown\n",
      "    Language: fi_FI\n",
      "    ID: com.apple.eloquence.fi-FI.Flo\n",
      "\n",
      "  Voice 38:\n",
      "    Name: Flo (French (Canada))\n",
      "    Gender: Unknown\n",
      "    Language: fr_CA\n",
      "    ID: com.apple.eloquence.fr-CA.Flo\n",
      "\n",
      "  Voice 39:\n",
      "    Name: Flo (French (France))\n",
      "    Gender: Unknown\n",
      "    Language: fr_FR\n",
      "    ID: com.apple.eloquence.fr-FR.Flo\n",
      "\n",
      "  Voice 40:\n",
      "    Name: Flo (Italian (Italy))\n",
      "    Gender: Unknown\n",
      "    Language: it_IT\n",
      "    ID: com.apple.eloquence.it-IT.Flo\n",
      "\n",
      "  Voice 41:\n",
      "    Name: Flo (Japanese (Japan))\n",
      "    Gender: Unknown\n",
      "    Language: ja_JP\n",
      "    ID: com.apple.eloquence.ja-JP.Flo\n",
      "\n",
      "  Voice 42:\n",
      "    Name: Flo (Korean (South Korea))\n",
      "    Gender: Unknown\n",
      "    Language: ko_KR\n",
      "    ID: com.apple.eloquence.ko-KR.Flo\n",
      "\n",
      "  Voice 43:\n",
      "    Name: Flo (Portuguese (Brazil))\n",
      "    Gender: Unknown\n",
      "    Language: pt_BR\n",
      "    ID: com.apple.eloquence.pt-BR.Flo\n",
      "\n",
      "  Voice 44:\n",
      "    Name: Flo (Chinese (China mainland))\n",
      "    Gender: Unknown\n",
      "    Language: zh_CN\n",
      "    ID: com.apple.eloquence.zh-CN.Flo\n",
      "\n",
      "  Voice 45:\n",
      "    Name: Flo (Chinese (Taiwan))\n",
      "    Gender: Unknown\n",
      "    Language: zh_TW\n",
      "    ID: com.apple.eloquence.zh-TW.Flo\n",
      "\n",
      "  Voice 46:\n",
      "    Name: Fred\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Fred\n",
      "\n",
      "  Voice 47:\n",
      "    Name: Good News\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.GoodNews\n",
      "\n",
      "  Voice 48:\n",
      "    Name: Grandma (German (Germany))\n",
      "    Gender: Unknown\n",
      "    Language: de_DE\n",
      "    ID: com.apple.eloquence.de-DE.Grandma\n",
      "\n",
      "  Voice 49:\n",
      "    Name: Grandma (English (UK))\n",
      "    Gender: Unknown\n",
      "    Language: en_GB\n",
      "    ID: com.apple.eloquence.en-GB.Grandma\n",
      "\n",
      "  Voice 50:\n",
      "    Name: Grandma (English (US))\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.eloquence.en-US.Grandma\n",
      "\n",
      "  Voice 51:\n",
      "    Name: Grandma (Spanish (Spain))\n",
      "    Gender: Unknown\n",
      "    Language: es_ES\n",
      "    ID: com.apple.eloquence.es-ES.Grandma\n",
      "\n",
      "  Voice 52:\n",
      "    Name: Grandma (Spanish (Mexico))\n",
      "    Gender: Unknown\n",
      "    Language: es_MX\n",
      "    ID: com.apple.eloquence.es-MX.Grandma\n",
      "\n",
      "  Voice 53:\n",
      "    Name: Grandma (Finnish (Finland))\n",
      "    Gender: Unknown\n",
      "    Language: fi_FI\n",
      "    ID: com.apple.eloquence.fi-FI.Grandma\n",
      "\n",
      "  Voice 54:\n",
      "    Name: Grandma (French (Canada))\n",
      "    Gender: Unknown\n",
      "    Language: fr_CA\n",
      "    ID: com.apple.eloquence.fr-CA.Grandma\n",
      "\n",
      "  Voice 55:\n",
      "    Name: Grandma (French (France))\n",
      "    Gender: Unknown\n",
      "    Language: fr_FR\n",
      "    ID: com.apple.eloquence.fr-FR.Grandma\n",
      "\n",
      "  Voice 56:\n",
      "    Name: Grandma (Italian (Italy))\n",
      "    Gender: Unknown\n",
      "    Language: it_IT\n",
      "    ID: com.apple.eloquence.it-IT.Grandma\n",
      "\n",
      "  Voice 57:\n",
      "    Name: Grandma (Japanese (Japan))\n",
      "    Gender: Unknown\n",
      "    Language: ja_JP\n",
      "    ID: com.apple.eloquence.ja-JP.Grandma\n",
      "\n",
      "  Voice 58:\n",
      "    Name: Grandma (Korean (South Korea))\n",
      "    Gender: Unknown\n",
      "    Language: ko_KR\n",
      "    ID: com.apple.eloquence.ko-KR.Grandma\n",
      "\n",
      "  Voice 59:\n",
      "    Name: Grandma (Portuguese (Brazil))\n",
      "    Gender: Unknown\n",
      "    Language: pt_BR\n",
      "    ID: com.apple.eloquence.pt-BR.Grandma\n",
      "\n",
      "  Voice 60:\n",
      "    Name: Grandma (Chinese (China mainland))\n",
      "    Gender: Unknown\n",
      "    Language: zh_CN\n",
      "    ID: com.apple.eloquence.zh-CN.Grandma\n",
      "\n",
      "  Voice 61:\n",
      "    Name: Grandma (Chinese (Taiwan))\n",
      "    Gender: Unknown\n",
      "    Language: zh_TW\n",
      "    ID: com.apple.eloquence.zh-TW.Grandma\n",
      "\n",
      "  Voice 62:\n",
      "    Name: Grandpa (German (Germany))\n",
      "    Gender: Unknown\n",
      "    Language: de_DE\n",
      "    ID: com.apple.eloquence.de-DE.Grandpa\n",
      "\n",
      "  Voice 63:\n",
      "    Name: Grandpa (English (UK))\n",
      "    Gender: Unknown\n",
      "    Language: en_GB\n",
      "    ID: com.apple.eloquence.en-GB.Grandpa\n",
      "\n",
      "  Voice 64:\n",
      "    Name: Grandpa (English (US))\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.eloquence.en-US.Grandpa\n",
      "\n",
      "  Voice 65:\n",
      "    Name: Grandpa (Spanish (Spain))\n",
      "    Gender: Unknown\n",
      "    Language: es_ES\n",
      "    ID: com.apple.eloquence.es-ES.Grandpa\n",
      "\n",
      "  Voice 66:\n",
      "    Name: Grandpa (Spanish (Mexico))\n",
      "    Gender: Unknown\n",
      "    Language: es_MX\n",
      "    ID: com.apple.eloquence.es-MX.Grandpa\n",
      "\n",
      "  Voice 67:\n",
      "    Name: Grandpa (Finnish (Finland))\n",
      "    Gender: Unknown\n",
      "    Language: fi_FI\n",
      "    ID: com.apple.eloquence.fi-FI.Grandpa\n",
      "\n",
      "  Voice 68:\n",
      "    Name: Grandpa (French (Canada))\n",
      "    Gender: Unknown\n",
      "    Language: fr_CA\n",
      "    ID: com.apple.eloquence.fr-CA.Grandpa\n",
      "\n",
      "  Voice 69:\n",
      "    Name: Grandpa (French (France))\n",
      "    Gender: Unknown\n",
      "    Language: fr_FR\n",
      "    ID: com.apple.eloquence.fr-FR.Grandpa\n",
      "\n",
      "  Voice 70:\n",
      "    Name: Grandpa (Italian (Italy))\n",
      "    Gender: Unknown\n",
      "    Language: it_IT\n",
      "    ID: com.apple.eloquence.it-IT.Grandpa\n",
      "\n",
      "  Voice 71:\n",
      "    Name: Grandpa (Japanese (Japan))\n",
      "    Gender: Unknown\n",
      "    Language: ja_JP\n",
      "    ID: com.apple.eloquence.ja-JP.Grandpa\n",
      "\n",
      "  Voice 72:\n",
      "    Name: Grandpa (Korean (South Korea))\n",
      "    Gender: Unknown\n",
      "    Language: ko_KR\n",
      "    ID: com.apple.eloquence.ko-KR.Grandpa\n",
      "\n",
      "  Voice 73:\n",
      "    Name: Grandpa (Portuguese (Brazil))\n",
      "    Gender: Unknown\n",
      "    Language: pt_BR\n",
      "    ID: com.apple.eloquence.pt-BR.Grandpa\n",
      "\n",
      "  Voice 74:\n",
      "    Name: Grandpa (Chinese (China mainland))\n",
      "    Gender: Unknown\n",
      "    Language: zh_CN\n",
      "    ID: com.apple.eloquence.zh-CN.Grandpa\n",
      "\n",
      "  Voice 75:\n",
      "    Name: Grandpa (Chinese (Taiwan))\n",
      "    Gender: Unknown\n",
      "    Language: zh_TW\n",
      "    ID: com.apple.eloquence.zh-TW.Grandpa\n",
      "\n",
      "  Voice 76:\n",
      "    Name: Jester\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Hysterical\n",
      "\n",
      "  Voice 77:\n",
      "    Name: Ioana\n",
      "    Gender: Unknown\n",
      "    Language: ro_RO\n",
      "    ID: com.apple.voice.compact.ro-RO.Ioana\n",
      "\n",
      "  Voice 78:\n",
      "    Name: Jacques\n",
      "    Gender: Unknown\n",
      "    Language: fr_FR\n",
      "    ID: com.apple.eloquence.fr-FR.Jacques\n",
      "\n",
      "  Voice 79:\n",
      "    Name: Joana\n",
      "    Gender: Unknown\n",
      "    Language: pt_PT\n",
      "    ID: com.apple.voice.compact.pt-PT.Joana\n",
      "\n",
      "  Voice 80:\n",
      "    Name: Junior\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Junior\n",
      "\n",
      "  Voice 81:\n",
      "    Name: Kanya\n",
      "    Gender: Unknown\n",
      "    Language: th_TH\n",
      "    ID: com.apple.voice.compact.th-TH.Kanya\n",
      "\n",
      "  Voice 82:\n",
      "    Name: Karen\n",
      "    Gender: Unknown\n",
      "    Language: en_AU\n",
      "    ID: com.apple.voice.compact.en-AU.Karen\n",
      "\n",
      "  Voice 83:\n",
      "    Name: Kathy\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Kathy\n",
      "\n",
      "  Voice 84:\n",
      "    Name: Kyoko\n",
      "    Gender: Unknown\n",
      "    Language: ja_JP\n",
      "    ID: com.apple.voice.compact.ja-JP.Kyoko\n",
      "\n",
      "  Voice 85:\n",
      "    Name: Lana\n",
      "    Gender: Unknown\n",
      "    Language: hr_HR\n",
      "    ID: com.apple.voice.compact.hr-HR.Lana\n",
      "\n",
      "  Voice 86:\n",
      "    Name: Laura\n",
      "    Gender: Unknown\n",
      "    Language: sk_SK\n",
      "    ID: com.apple.voice.compact.sk-SK.Laura\n",
      "\n",
      "  Voice 87:\n",
      "    Name: Lekha\n",
      "    Gender: Unknown\n",
      "    Language: hi_IN\n",
      "    ID: com.apple.voice.compact.hi-IN.Lekha\n",
      "\n",
      "  Voice 88:\n",
      "    Name: Lesya\n",
      "    Gender: Unknown\n",
      "    Language: uk_UA\n",
      "    ID: com.apple.voice.compact.uk-UA.Lesya\n",
      "\n",
      "  Voice 89:\n",
      "    Name: Linh\n",
      "    Gender: Unknown\n",
      "    Language: vi_VN\n",
      "    ID: com.apple.voice.compact.vi-VN.Linh\n",
      "\n",
      "  Voice 90:\n",
      "    Name: Luciana\n",
      "    Gender: Unknown\n",
      "    Language: pt_BR\n",
      "    ID: com.apple.voice.compact.pt-BR.Luciana\n",
      "\n",
      "  Voice 91:\n",
      "    Name: Majed\n",
      "    Gender: Unknown\n",
      "    Language: ar_001\n",
      "    ID: com.apple.voice.compact.ar-001.Maged\n",
      "\n",
      "  Voice 92:\n",
      "    Name: TÃ¼nde\n",
      "    Gender: Unknown\n",
      "    Language: hu_HU\n",
      "    ID: com.apple.voice.compact.hu-HU.Mariska\n",
      "\n",
      "  Voice 93:\n",
      "    Name: Meijia\n",
      "    Gender: Unknown\n",
      "    Language: zh_TW\n",
      "    ID: com.apple.voice.compact.zh-TW.Meijia\n",
      "\n",
      "  Voice 94:\n",
      "    Name: Melina\n",
      "    Gender: Unknown\n",
      "    Language: el_GR\n",
      "    ID: com.apple.voice.compact.el-GR.Melina\n",
      "\n",
      "  Voice 95:\n",
      "    Name: Milena\n",
      "    Gender: Unknown\n",
      "    Language: ru_RU\n",
      "    ID: com.apple.voice.compact.ru-RU.Milena\n",
      "\n",
      "  Voice 96:\n",
      "    Name: Moira\n",
      "    Gender: Unknown\n",
      "    Language: en_IE\n",
      "    ID: com.apple.voice.compact.en-IE.Moira\n",
      "\n",
      "  Voice 97:\n",
      "    Name: MÃ³nica\n",
      "    Gender: Unknown\n",
      "    Language: es_ES\n",
      "    ID: com.apple.voice.compact.es-ES.Monica\n",
      "\n",
      "  Voice 98:\n",
      "    Name: Montse\n",
      "    Gender: Unknown\n",
      "    Language: ca_ES\n",
      "    ID: com.apple.voice.compact.ca-ES.Montserrat\n",
      "\n",
      "  Voice 99:\n",
      "    Name: Nora\n",
      "    Gender: Unknown\n",
      "    Language: nb_NO\n",
      "    ID: com.apple.voice.compact.nb-NO.Nora\n",
      "\n",
      "  Voice 100:\n",
      "    Name: Organ\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Organ\n",
      "\n",
      "  Voice 101:\n",
      "    Name: Paulina\n",
      "    Gender: Unknown\n",
      "    Language: es_MX\n",
      "    ID: com.apple.voice.compact.es-MX.Paulina\n",
      "\n",
      "  Voice 102:\n",
      "    Name: Superstar\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Princess\n",
      "\n",
      "  Voice 103:\n",
      "    Name: Ralph\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Ralph\n",
      "\n",
      "  Voice 104:\n",
      "    Name: Reed (German (Germany))\n",
      "    Gender: Unknown\n",
      "    Language: de_DE\n",
      "    ID: com.apple.eloquence.de-DE.Reed\n",
      "\n",
      "  Voice 105:\n",
      "    Name: Reed (English (UK))\n",
      "    Gender: Unknown\n",
      "    Language: en_GB\n",
      "    ID: com.apple.eloquence.en-GB.Reed\n",
      "\n",
      "  Voice 106:\n",
      "    Name: Reed (English (US))\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.eloquence.en-US.Reed\n",
      "\n",
      "  Voice 107:\n",
      "    Name: Reed (Spanish (Spain))\n",
      "    Gender: Unknown\n",
      "    Language: es_ES\n",
      "    ID: com.apple.eloquence.es-ES.Reed\n",
      "\n",
      "  Voice 108:\n",
      "    Name: Reed (Spanish (Mexico))\n",
      "    Gender: Unknown\n",
      "    Language: es_MX\n",
      "    ID: com.apple.eloquence.es-MX.Reed\n",
      "\n",
      "  Voice 109:\n",
      "    Name: Reed (Finnish (Finland))\n",
      "    Gender: Unknown\n",
      "    Language: fi_FI\n",
      "    ID: com.apple.eloquence.fi-FI.Reed\n",
      "\n",
      "  Voice 110:\n",
      "    Name: Reed (French (Canada))\n",
      "    Gender: Unknown\n",
      "    Language: fr_CA\n",
      "    ID: com.apple.eloquence.fr-CA.Reed\n",
      "\n",
      "  Voice 111:\n",
      "    Name: Reed (Italian (Italy))\n",
      "    Gender: Unknown\n",
      "    Language: it_IT\n",
      "    ID: com.apple.eloquence.it-IT.Reed\n",
      "\n",
      "  Voice 112:\n",
      "    Name: Reed (Japanese (Japan))\n",
      "    Gender: Unknown\n",
      "    Language: ja_JP\n",
      "    ID: com.apple.eloquence.ja-JP.Reed\n",
      "\n",
      "  Voice 113:\n",
      "    Name: Reed (Korean (South Korea))\n",
      "    Gender: Unknown\n",
      "    Language: ko_KR\n",
      "    ID: com.apple.eloquence.ko-KR.Reed\n",
      "\n",
      "  Voice 114:\n",
      "    Name: Reed (Portuguese (Brazil))\n",
      "    Gender: Unknown\n",
      "    Language: pt_BR\n",
      "    ID: com.apple.eloquence.pt-BR.Reed\n",
      "\n",
      "  Voice 115:\n",
      "    Name: Reed (Chinese (China mainland))\n",
      "    Gender: Unknown\n",
      "    Language: zh_CN\n",
      "    ID: com.apple.eloquence.zh-CN.Reed\n",
      "\n",
      "  Voice 116:\n",
      "    Name: Reed (Chinese (Taiwan))\n",
      "    Gender: Unknown\n",
      "    Language: zh_TW\n",
      "    ID: com.apple.eloquence.zh-TW.Reed\n",
      "\n",
      "  Voice 117:\n",
      "    Name: Rishi\n",
      "    Gender: Unknown\n",
      "    Language: en_IN\n",
      "    ID: com.apple.voice.compact.en-IN.Rishi\n",
      "\n",
      "  Voice 118:\n",
      "    Name: Rocko (German (Germany))\n",
      "    Gender: Unknown\n",
      "    Language: de_DE\n",
      "    ID: com.apple.eloquence.de-DE.Rocko\n",
      "\n",
      "  Voice 119:\n",
      "    Name: Rocko (English (UK))\n",
      "    Gender: Unknown\n",
      "    Language: en_GB\n",
      "    ID: com.apple.eloquence.en-GB.Rocko\n",
      "\n",
      "  Voice 120:\n",
      "    Name: Rocko (English (US))\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.eloquence.en-US.Rocko\n",
      "\n",
      "  Voice 121:\n",
      "    Name: Rocko (Spanish (Spain))\n",
      "    Gender: Unknown\n",
      "    Language: es_ES\n",
      "    ID: com.apple.eloquence.es-ES.Rocko\n",
      "\n",
      "  Voice 122:\n",
      "    Name: Rocko (Spanish (Mexico))\n",
      "    Gender: Unknown\n",
      "    Language: es_MX\n",
      "    ID: com.apple.eloquence.es-MX.Rocko\n",
      "\n",
      "  Voice 123:\n",
      "    Name: Rocko (Finnish (Finland))\n",
      "    Gender: Unknown\n",
      "    Language: fi_FI\n",
      "    ID: com.apple.eloquence.fi-FI.Rocko\n",
      "\n",
      "  Voice 124:\n",
      "    Name: Rocko (French (Canada))\n",
      "    Gender: Unknown\n",
      "    Language: fr_CA\n",
      "    ID: com.apple.eloquence.fr-CA.Rocko\n",
      "\n",
      "  Voice 125:\n",
      "    Name: Rocko (French (France))\n",
      "    Gender: Unknown\n",
      "    Language: fr_FR\n",
      "    ID: com.apple.eloquence.fr-FR.Rocko\n",
      "\n",
      "  Voice 126:\n",
      "    Name: Rocko (Italian (Italy))\n",
      "    Gender: Unknown\n",
      "    Language: it_IT\n",
      "    ID: com.apple.eloquence.it-IT.Rocko\n",
      "\n",
      "  Voice 127:\n",
      "    Name: Rocko (Japanese (Japan))\n",
      "    Gender: Unknown\n",
      "    Language: ja_JP\n",
      "    ID: com.apple.eloquence.ja-JP.Rocko\n",
      "\n",
      "  Voice 128:\n",
      "    Name: Rocko (Korean (South Korea))\n",
      "    Gender: Unknown\n",
      "    Language: ko_KR\n",
      "    ID: com.apple.eloquence.ko-KR.Rocko\n",
      "\n",
      "  Voice 129:\n",
      "    Name: Rocko (Portuguese (Brazil))\n",
      "    Gender: Unknown\n",
      "    Language: pt_BR\n",
      "    ID: com.apple.eloquence.pt-BR.Rocko\n",
      "\n",
      "  Voice 130:\n",
      "    Name: Rocko (Chinese (China mainland))\n",
      "    Gender: Unknown\n",
      "    Language: zh_CN\n",
      "    ID: com.apple.eloquence.zh-CN.Rocko\n",
      "\n",
      "  Voice 131:\n",
      "    Name: Rocko (Chinese (Taiwan))\n",
      "    Gender: Unknown\n",
      "    Language: zh_TW\n",
      "    ID: com.apple.eloquence.zh-TW.Rocko\n",
      "\n",
      "  Voice 132:\n",
      "    Name: Samantha\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.voice.compact.en-US.Samantha\n",
      "\n",
      "  Voice 133:\n",
      "    Name: Sandy (German (Germany))\n",
      "    Gender: Unknown\n",
      "    Language: de_DE\n",
      "    ID: com.apple.eloquence.de-DE.Sandy\n",
      "\n",
      "  Voice 134:\n",
      "    Name: Sandy (English (UK))\n",
      "    Gender: Unknown\n",
      "    Language: en_GB\n",
      "    ID: com.apple.eloquence.en-GB.Sandy\n",
      "\n",
      "  Voice 135:\n",
      "    Name: Sandy (English (US))\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.eloquence.en-US.Sandy\n",
      "\n",
      "  Voice 136:\n",
      "    Name: Sandy (Spanish (Spain))\n",
      "    Gender: Unknown\n",
      "    Language: es_ES\n",
      "    ID: com.apple.eloquence.es-ES.Sandy\n",
      "\n",
      "  Voice 137:\n",
      "    Name: Sandy (Spanish (Mexico))\n",
      "    Gender: Unknown\n",
      "    Language: es_MX\n",
      "    ID: com.apple.eloquence.es-MX.Sandy\n",
      "\n",
      "  Voice 138:\n",
      "    Name: Sandy (Finnish (Finland))\n",
      "    Gender: Unknown\n",
      "    Language: fi_FI\n",
      "    ID: com.apple.eloquence.fi-FI.Sandy\n",
      "\n",
      "  Voice 139:\n",
      "    Name: Sandy (French (Canada))\n",
      "    Gender: Unknown\n",
      "    Language: fr_CA\n",
      "    ID: com.apple.eloquence.fr-CA.Sandy\n",
      "\n",
      "  Voice 140:\n",
      "    Name: Sandy (French (France))\n",
      "    Gender: Unknown\n",
      "    Language: fr_FR\n",
      "    ID: com.apple.eloquence.fr-FR.Sandy\n",
      "\n",
      "  Voice 141:\n",
      "    Name: Sandy (Italian (Italy))\n",
      "    Gender: Unknown\n",
      "    Language: it_IT\n",
      "    ID: com.apple.eloquence.it-IT.Sandy\n",
      "\n",
      "  Voice 142:\n",
      "    Name: Sandy (Japanese (Japan))\n",
      "    Gender: Unknown\n",
      "    Language: ja_JP\n",
      "    ID: com.apple.eloquence.ja-JP.Sandy\n",
      "\n",
      "  Voice 143:\n",
      "    Name: Sandy (Korean (South Korea))\n",
      "    Gender: Unknown\n",
      "    Language: ko_KR\n",
      "    ID: com.apple.eloquence.ko-KR.Sandy\n",
      "\n",
      "  Voice 144:\n",
      "    Name: Sandy (Portuguese (Brazil))\n",
      "    Gender: Unknown\n",
      "    Language: pt_BR\n",
      "    ID: com.apple.eloquence.pt-BR.Sandy\n",
      "\n",
      "  Voice 145:\n",
      "    Name: Sandy (Chinese (China mainland))\n",
      "    Gender: Unknown\n",
      "    Language: zh_CN\n",
      "    ID: com.apple.eloquence.zh-CN.Sandy\n",
      "\n",
      "  Voice 146:\n",
      "    Name: Sandy (Chinese (Taiwan))\n",
      "    Gender: Unknown\n",
      "    Language: zh_TW\n",
      "    ID: com.apple.eloquence.zh-TW.Sandy\n",
      "\n",
      "  Voice 147:\n",
      "    Name: Sara\n",
      "    Gender: Unknown\n",
      "    Language: da_DK\n",
      "    ID: com.apple.voice.compact.da-DK.Sara\n",
      "\n",
      "  Voice 148:\n",
      "    Name: Satu\n",
      "    Gender: Unknown\n",
      "    Language: fi_FI\n",
      "    ID: com.apple.voice.compact.fi-FI.Satu\n",
      "\n",
      "  Voice 149:\n",
      "    Name: Shelley (German (Germany))\n",
      "    Gender: Unknown\n",
      "    Language: de_DE\n",
      "    ID: com.apple.eloquence.de-DE.Shelley\n",
      "\n",
      "  Voice 150:\n",
      "    Name: Shelley (English (UK))\n",
      "    Gender: Unknown\n",
      "    Language: en_GB\n",
      "    ID: com.apple.eloquence.en-GB.Shelley\n",
      "\n",
      "  Voice 151:\n",
      "    Name: Shelley (English (US))\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.eloquence.en-US.Shelley\n",
      "\n",
      "  Voice 152:\n",
      "    Name: Shelley (Spanish (Spain))\n",
      "    Gender: Unknown\n",
      "    Language: es_ES\n",
      "    ID: com.apple.eloquence.es-ES.Shelley\n",
      "\n",
      "  Voice 153:\n",
      "    Name: Shelley (Spanish (Mexico))\n",
      "    Gender: Unknown\n",
      "    Language: es_MX\n",
      "    ID: com.apple.eloquence.es-MX.Shelley\n",
      "\n",
      "  Voice 154:\n",
      "    Name: Shelley (Finnish (Finland))\n",
      "    Gender: Unknown\n",
      "    Language: fi_FI\n",
      "    ID: com.apple.eloquence.fi-FI.Shelley\n",
      "\n",
      "  Voice 155:\n",
      "    Name: Shelley (French (Canada))\n",
      "    Gender: Unknown\n",
      "    Language: fr_CA\n",
      "    ID: com.apple.eloquence.fr-CA.Shelley\n",
      "\n",
      "  Voice 156:\n",
      "    Name: Shelley (French (France))\n",
      "    Gender: Unknown\n",
      "    Language: fr_FR\n",
      "    ID: com.apple.eloquence.fr-FR.Shelley\n",
      "\n",
      "  Voice 157:\n",
      "    Name: Shelley (Italian (Italy))\n",
      "    Gender: Unknown\n",
      "    Language: it_IT\n",
      "    ID: com.apple.eloquence.it-IT.Shelley\n",
      "\n",
      "  Voice 158:\n",
      "    Name: Shelley (Japanese (Japan))\n",
      "    Gender: Unknown\n",
      "    Language: ja_JP\n",
      "    ID: com.apple.eloquence.ja-JP.Shelley\n",
      "\n",
      "  Voice 159:\n",
      "    Name: Shelley (Korean (South Korea))\n",
      "    Gender: Unknown\n",
      "    Language: ko_KR\n",
      "    ID: com.apple.eloquence.ko-KR.Shelley\n",
      "\n",
      "  Voice 160:\n",
      "    Name: Shelley (Portuguese (Brazil))\n",
      "    Gender: Unknown\n",
      "    Language: pt_BR\n",
      "    ID: com.apple.eloquence.pt-BR.Shelley\n",
      "\n",
      "  Voice 161:\n",
      "    Name: Shelley (Chinese (China mainland))\n",
      "    Gender: Unknown\n",
      "    Language: zh_CN\n",
      "    ID: com.apple.eloquence.zh-CN.Shelley\n",
      "\n",
      "  Voice 162:\n",
      "    Name: Shelley (Chinese (Taiwan))\n",
      "    Gender: Unknown\n",
      "    Language: zh_TW\n",
      "    ID: com.apple.eloquence.zh-TW.Shelley\n",
      "\n",
      "  Voice 163:\n",
      "    Name: Sinji\n",
      "    Gender: Unknown\n",
      "    Language: zh_HK\n",
      "    ID: com.apple.voice.compact.zh-HK.Sinji\n",
      "\n",
      "  Voice 164:\n",
      "    Name: Tessa\n",
      "    Gender: Unknown\n",
      "    Language: en_ZA\n",
      "    ID: com.apple.voice.compact.en-ZA.Tessa\n",
      "\n",
      "  Voice 165:\n",
      "    Name: Thomas\n",
      "    Gender: Unknown\n",
      "    Language: fr_FR\n",
      "    ID: com.apple.voice.compact.fr-FR.Thomas\n",
      "\n",
      "  Voice 166:\n",
      "    Name: Tina\n",
      "    Gender: Unknown\n",
      "    Language: sl_SI\n",
      "    ID: com.apple.voice.compact.sl-SI.Tina\n",
      "\n",
      "  Voice 167:\n",
      "    Name: Tingting\n",
      "    Gender: Unknown\n",
      "    Language: zh_CN\n",
      "    ID: com.apple.voice.compact.zh-CN.Tingting\n",
      "\n",
      "  Voice 168:\n",
      "    Name: Trinoids\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Trinoids\n",
      "\n",
      "  Voice 169:\n",
      "    Name: Vani\n",
      "    Gender: Unknown\n",
      "    Language: ta_IN\n",
      "    ID: com.apple.voice.compact.ta-IN.Vani\n",
      "\n",
      "  Voice 170:\n",
      "    Name: Whisper\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Whisper\n",
      "\n",
      "  Voice 171:\n",
      "    Name: Xander\n",
      "    Gender: Unknown\n",
      "    Language: nl_NL\n",
      "    ID: com.apple.voice.compact.nl-NL.Xander\n",
      "\n",
      "  Voice 172:\n",
      "    Name: Yelda\n",
      "    Gender: Unknown\n",
      "    Language: tr_TR\n",
      "    ID: com.apple.voice.compact.tr-TR.Yelda\n",
      "\n",
      "  Voice 173:\n",
      "    Name: Yuna\n",
      "    Gender: Unknown\n",
      "    Language: ko_KR\n",
      "    ID: com.apple.voice.compact.ko-KR.Yuna\n",
      "\n",
      "  Voice 174:\n",
      "    Name: Zarvox\n",
      "    Gender: Unknown\n",
      "    Language: en_US\n",
      "    ID: com.apple.speech.synthesis.voice.Zarvox\n",
      "\n",
      "  Voice 175:\n",
      "    Name: Zosia\n",
      "    Gender: Unknown\n",
      "    Language: pl_PL\n",
      "    ID: com.apple.voice.compact.pl-PL.Zosia\n",
      "\n",
      "  Voice 176:\n",
      "    Name: Zuzana\n",
      "    Gender: Unknown\n",
      "    Language: cs_CZ\n",
      "    ID: com.apple.voice.compact.cs-CZ.Zuzana\n"
     ]
    }
   ],
   "source": [
    "import pyttsx3\n",
    "\n",
    "print(\"ğŸ—£ï¸ Setting up Text-to-Speech...\")\n",
    "\n",
    "# Initialize the TTS engine\n",
    "tts_engine = pyttsx3.init()\n",
    "\n",
    "# Let's explore the available voices\n",
    "def explore_voices():\n",
    "    \"\"\"Discover what voices are available\"\"\"\n",
    "    print(\"\\nğŸ­ EXPLORING AVAILABLE VOICES\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    voices = tts_engine.getProperty('voices')\n",
    "    print(f\"ğŸ” Found {len(voices)} voices on your system:\")\n",
    "    \n",
    "    for i, voice in enumerate(voices):\n",
    "        # Get voice info\n",
    "        name = voice.name\n",
    "        gender = \"Female\" if \"female\" in name.lower() else \"Male\" if \"male\" in name.lower() else \"Unknown\"\n",
    "        language = voice.languages[0] if voice.languages else \"Unknown\"\n",
    "        \n",
    "        print(f\"\\n  Voice {i}:\")\n",
    "        print(f\"    Name: {name}\")\n",
    "        print(f\"    Gender: {gender}\")\n",
    "        print(f\"    Language: {language}\")\n",
    "        print(f\"    ID: {voice.id}\")\n",
    "    \n",
    "    return voices\n",
    "\n",
    "# Explore available voices\n",
    "available_voices = explore_voices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸµ Experiment 2: Making Your Computer Talk\n",
    " \n",
    "Let's make our computer speak with different voices and settings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸª TEXT-TO-SPEECH DEMO\n",
      "===================================\n",
      "ğŸ›ï¸ Current settings:\n",
      "   Speed: 200.0 words per minute\n",
      "   Volume: 1.0\n",
      "\n",
      "ğŸ¤ Demo 1: Normal speech\n",
      "\n",
      "ğŸŒ Demo 2: Slow speech\n",
      "\n",
      "ğŸƒ Demo 3: Fast speech\n",
      "\n",
      "ğŸ‘¥ Demo 4: Different voice\n",
      "\n",
      "âœ… Text-to-Speech demo complete!\n"
     ]
    }
   ],
   "source": [
    "def text_to_speech_demo():\n",
    "    \"\"\"Demonstrate text-to-speech with different settings\"\"\"\n",
    "    print(\"\\nğŸª TEXT-TO-SPEECH DEMO\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    test_message = \"Hello! I am your voice agent. I can speak in different voices and speeds!\"\n",
    "    \n",
    "    # Get current settings\n",
    "    current_rate = tts_engine.getProperty('rate')\n",
    "    current_volume = tts_engine.getProperty('volume')\n",
    "    \n",
    "    print(f\"ğŸ›ï¸ Current settings:\")\n",
    "    print(f\"   Speed: {current_rate} words per minute\")\n",
    "    print(f\"   Volume: {current_volume}\")\n",
    "    \n",
    "    # Demo 1: Normal speech\n",
    "    print(f\"\\nğŸ¤ Demo 1: Normal speech\")\n",
    "    tts_engine.setProperty('rate', 200)\n",
    "    tts_engine.setProperty('volume', 0.8)\n",
    "    tts_engine.say(\"Hello! This is normal speech.\")\n",
    "    tts_engine.runAndWait()\n",
    "    \n",
    "    # Demo 2: Slow speech\n",
    "    print(f\"\\nğŸŒ Demo 2: Slow speech\")\n",
    "    tts_engine.setProperty('rate', 120)\n",
    "    tts_engine.say(\"This... is... slow... speech.\")\n",
    "    tts_engine.runAndWait()\n",
    "    \n",
    "    # Demo 3: Fast speech\n",
    "    print(f\"\\nğŸƒ Demo 3: Fast speech\")\n",
    "    tts_engine.setProperty('rate', 300)\n",
    "    tts_engine.say(\"This is very fast speech! Can you understand me?\")\n",
    "    tts_engine.runAndWait()\n",
    "    \n",
    "    # Demo 4: Different voice (if available)\n",
    "    if len(available_voices) > 1:\n",
    "        print(f\"\\nğŸ‘¥ Demo 4: Different voice\")\n",
    "        tts_engine.setProperty('voice', available_voices[1].id)\n",
    "        tts_engine.setProperty('rate', 200)\n",
    "        tts_engine.say(\"Now I'm speaking with a different voice!\")\n",
    "        tts_engine.runAndWait()\n",
    "        \n",
    "        # Reset to first voice\n",
    "        tts_engine.setProperty('voice', available_voices[0].id)\n",
    "    \n",
    "    print(\"\\nâœ… Text-to-Speech demo complete!\")\n",
    "\n",
    "# Run the demo\n",
    "text_to_speech_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Step 4: Building Our Voice Agent Class\n",
    " \n",
    "Now let's put everything together! We'll create a Voice Agent class that can listen, think, and speak.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPT-4o-mini connected successfully from .env file!\n",
      "ğŸ¤– Sophia is ready to help in text-only mode!\n",
      "ğŸ” Searching for US female voices...\n",
      "ğŸ­ Selected US female voice: Samantha\n",
      "âœ… GPT-4o-mini connected successfully from .env file!\n",
      "ğŸ¤– Sophia is ready to help with voice enabled!\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import random\n",
    "import wikipedia\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class VoiceAgent:\n",
    "    \"\"\"A simple voice agent that can listen, process, and respond\"\"\"\n",
    "    \n",
    "    def __init__(self, name=\"Sophia\", enable_tts=True):\n",
    "        \"\"\"Initialize the voice agent\"\"\"\n",
    "        self.name = name\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.microphone = sr.Microphone()\n",
    "        \n",
    "        # TTS control\n",
    "        self.enable_tts = enable_tts\n",
    "        self.voice_id = None\n",
    "        self.voice_rate = 175\n",
    "        self.voice_volume = 0.9\n",
    "        \n",
    "        # Find and store the best voice\n",
    "        if self.enable_tts:\n",
    "            self.find_best_voice()\n",
    "        \n",
    "        # Initialize OpenAI client for GPT-4o-mini\n",
    "        self.setup_openai()\n",
    "        \n",
    "        # Conversation history for context\n",
    "        self.conversation_history = []\n",
    "        \n",
    "        # Agent's knowledge and responses\n",
    "        self.responses = {\n",
    "            'greetings': [\n",
    "                f\"Hello! I'm {self.name}, your voice agent!\",\n",
    "                f\"Hi there! {self.name} here, ready to help!\",\n",
    "                f\"Greetings! I'm {self.name}. How can I assist you?\"\n",
    "            ],\n",
    "            'farewell': [\n",
    "                \"Goodbye! It was nice talking with you!\",\n",
    "                \"See you later! Have a great day!\",\n",
    "                \"Farewell! Come back anytime!\"\n",
    "            ],\n",
    "            'thanks': [\n",
    "                \"You're welcome! Happy to help!\",\n",
    "                \"No problem at all!\",\n",
    "                \"Glad I could assist you!\"\n",
    "            ],\n",
    "            'unknown': [\n",
    "                \"I'm still learning. Could you try asking differently?\",\n",
    "                \"That's interesting! I don't know about that yet.\",\n",
    "                \"I'm not sure about that. Can you teach me?\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        tts_status = \"with voice enabled\" if self.enable_tts else \"in text-only mode\"\n",
    "        print(f\"ğŸ¤– {self.name} is ready to help {tts_status}!\")\n",
    "    \n",
    "    def find_best_voice(self):\n",
    "        \"\"\"Find and store the best US female voice\"\"\"\n",
    "        try:\n",
    "            temp_engine = pyttsx3.init()\n",
    "            voices = temp_engine.getProperty('voices')\n",
    "            \n",
    "            if voices:\n",
    "                print(\"ğŸ” Searching for US female voices...\")\n",
    "                \n",
    "                # Priority 1: Look for US English female voices\n",
    "                us_female_keywords = [\n",
    "                    'english (united states)', 'en-us', 'usa', 'american',\n",
    "                    'zira', 'cortana', 'eva', 'samantha', 'alex'\n",
    "                ]\n",
    "                \n",
    "                for voice in voices:\n",
    "                    voice_name = voice.name.lower()\n",
    "                    voice_id = voice.id.lower()\n",
    "                    \n",
    "                    # Check if voice is US English and female\n",
    "                    is_us = any(keyword in voice_name or keyword in voice_id for keyword in us_female_keywords)\n",
    "                    is_female = any(keyword in voice_name for keyword in ['female', 'woman', 'girl', 'zira', 'cortana', 'eva', 'samantha'])\n",
    "                    \n",
    "                    if is_us and is_female:\n",
    "                        self.voice_id = voice.id\n",
    "                        print(f\"ğŸ­ Selected US female voice: {voice.name}\")\n",
    "                        break\n",
    "                \n",
    "                # Fallback to any female voice\n",
    "                if not self.voice_id:\n",
    "                    for voice in voices:\n",
    "                        voice_name = voice.name.lower()\n",
    "                        if any(keyword in voice_name for keyword in ['female', 'woman', 'girl', 'zira', 'samantha']):\n",
    "                            self.voice_id = voice.id\n",
    "                            print(f\"ğŸ­ Selected female voice: {voice.name}\")\n",
    "                            break\n",
    "                \n",
    "                # Final fallback\n",
    "                if not self.voice_id and len(voices) > 1:\n",
    "                    self.voice_id = voices[1].id\n",
    "                    print(f\"ğŸ­ Fallback voice selected: {voices[1].name}\")\n",
    "            \n",
    "            # Clean up temp engine\n",
    "            temp_engine.stop()\n",
    "            del temp_engine\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Voice detection error: {e}\")\n",
    "            self.voice_id = None\n",
    "    \n",
    "    def setup_openai(self):\n",
    "        \"\"\"Setup OpenAI API for GPT-4o-mini from .env file\"\"\"\n",
    "        try:\n",
    "            # Load environment variables from .env file\n",
    "            load_dotenv()\n",
    "            \n",
    "            # Get API key from environment variable\n",
    "            api_key = os.getenv('OPENAI_API_KEY')\n",
    "            \n",
    "            if not api_key:\n",
    "                print(\"âŒ OPENAI_API_KEY not found in .env file!\")\n",
    "                print(\"ğŸ“ Please add your API key to .env file:\")\n",
    "                print(\"   OPENAI_API_KEY=your_api_key_here\")\n",
    "                print(\"âš ï¸ Continuing without AI features. Using basic responses only.\")\n",
    "                self.openai_client = None\n",
    "                return\n",
    "            \n",
    "            # Initialize OpenAI client with new API (v1.0+)\n",
    "            self.openai_client = openai.OpenAI(api_key=api_key)\n",
    "            print(\"âœ… GPT-4o-mini connected successfully from .env file!\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"âŒ python-dotenv not installed!\")\n",
    "            print(\"ğŸ“¦ Please install it: pip install python-dotenv\")\n",
    "            print(\"âš ï¸ Continuing without AI features. Using basic responses only.\")\n",
    "            self.openai_client = None\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error setting up OpenAI: {e}\")\n",
    "            print(\"âš ï¸ Continuing without AI features. Using basic responses only.\")\n",
    "            self.openai_client = None\n",
    "    \n",
    "    def get_ai_response(self, user_input):\n",
    "        \"\"\"Get intelligent response from GPT-4o-mini\"\"\"\n",
    "        if not self.openai_client:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Prepare conversation context\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": \"You are Sophia, a helpful and friendly voice assistant. Keep responses concise (1-3 sentences) since they will be spoken aloud. Use a warm, encouraging tone.\"}\n",
    "            ]\n",
    "            \n",
    "            # Add recent conversation history for context\n",
    "            for msg in self.conversation_history[-6:]:  # Last 6 messages for context\n",
    "                messages.append(msg)\n",
    "            \n",
    "            # Add current user input\n",
    "            messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "            \n",
    "            # Get response from GPT-4o-mini using new API\n",
    "            response = self.openai_client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages,\n",
    "                max_tokens=150,  # Keep responses concise for speech\n",
    "                temperature=0.7,  # Balanced creativity and consistency\n",
    "            )\n",
    "            \n",
    "            ai_response = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Update conversation history\n",
    "            self.conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "            \n",
    "            # Keep history manageable\n",
    "            if len(self.conversation_history) > 20:\n",
    "                self.conversation_history = self.conversation_history[-20:]\n",
    "            \n",
    "            return ai_response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ AI Error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def speak(self, text):\n",
    "        \"\"\"Convert text to speech or text-only mode\"\"\"\n",
    "        print(f\"ğŸ¤– {self.name}: {text}\")\n",
    "        \n",
    "        if not self.enable_tts:\n",
    "            print(\"ğŸ“ (Text-only mode)\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            import subprocess\n",
    "            import platform\n",
    "            \n",
    "            # Use system TTS instead of pyttsx3 for Jupyter\n",
    "            system = platform.system()\n",
    "            \n",
    "            if system == \"Darwin\":  # macOS\n",
    "                subprocess.run([\"say\", text], check=True)\n",
    "            elif system == \"Windows\":\n",
    "                subprocess.run([\"powershell\", \"-Command\", f\"Add-Type -AssemblyName System.Speech; (New-Object System.Speech.Synthesis.SpeechSynthesizer).Speak('{text}')\"], check=True)\n",
    "            elif system == \"Linux\":\n",
    "                subprocess.run([\"espeak\", text], check=True)\n",
    "            else:\n",
    "                print(\"ğŸ”‡ System TTS not available on this platform\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"ğŸ”‡ System TTS error: {e}\")\n",
    "    \n",
    "    def listen(self):\n",
    "        \"\"\"Listen to user speech and convert to text\"\"\"\n",
    "        try:\n",
    "            with self.microphone as source:\n",
    "                print(\"ğŸ§ Listening...\")\n",
    "                # Adjust for ambient noise\n",
    "                self.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "                # Listen for audio\n",
    "                audio = self.recognizer.listen(source, timeout=5, phrase_time_limit=5)\n",
    "                \n",
    "            print(\"ğŸ”„ Processing...\")\n",
    "            # Convert speech to text\n",
    "            text = self.recognizer.recognize_google(audio).lower()\n",
    "            print(f\"ğŸ‘¤ You said: '{text}'\")\n",
    "            return text\n",
    "            \n",
    "        except sr.WaitTimeoutError:\n",
    "            self.speak(\"I didn't hear anything. Could you try again?\")\n",
    "            return \"\"\n",
    "        except sr.UnknownValueError:\n",
    "            self.speak(\"I couldn't understand that. Could you speak more clearly?\")\n",
    "            return \"\"\n",
    "        except sr.RequestError:\n",
    "            self.speak(\"Sorry, I'm having trouble with my speech recognition service.\")\n",
    "            return \"\"\n",
    "    \n",
    "    def get_current_time(self):\n",
    "        \"\"\"Get current time\"\"\"\n",
    "        now = datetime.datetime.now()\n",
    "        time_str = now.strftime(\"%I:%M %p\")\n",
    "        return f\"The current time is {time_str}\"\n",
    "    \n",
    "    def get_current_date(self):\n",
    "        \"\"\"Get current date\"\"\"\n",
    "        today = datetime.date.today()\n",
    "        date_str = today.strftime(\"%B %d, %Y\")\n",
    "        return f\"Today is {date_str}\"\n",
    "    \n",
    "    def search_wikipedia(self, query):\n",
    "        \"\"\"Search Wikipedia for information\"\"\"\n",
    "        try:\n",
    "            # Remove common words\n",
    "            query = query.replace(\"tell me about\", \"\").replace(\"what is\", \"\").strip()\n",
    "            if not query:\n",
    "                return \"I need something to search for!\"\n",
    "            \n",
    "            print(f\"ğŸ” Searching for: {query}\")\n",
    "            summary = wikipedia.summary(query, sentences=2)\n",
    "            return summary\n",
    "        except wikipedia.exceptions.DisambiguationError:\n",
    "            return f\"There are multiple entries for {query}. Could you be more specific?\"\n",
    "        except wikipedia.exceptions.PageError:\n",
    "            return f\"I couldn't find information about {query}.\"\n",
    "        except:\n",
    "            return \"I had trouble searching for that information.\"\n",
    "    \n",
    "    def simple_math(self, command):\n",
    "        \"\"\"Perform simple math operations\"\"\"\n",
    "        try:\n",
    "            # Replace words with symbols\n",
    "            command = command.replace(\"plus\", \"+\").replace(\"add\", \"+\")\n",
    "            command = command.replace(\"minus\", \"-\").replace(\"subtract\", \"-\")\n",
    "            command = command.replace(\"times\", \"*\").replace(\"multiply\", \"*\")\n",
    "            command = command.replace(\"divided by\", \"/\").replace(\"divide\", \"/\")\n",
    "            \n",
    "            # Extract numbers and operation\n",
    "            words = command.split()\n",
    "            numbers = []\n",
    "            operation = None\n",
    "            \n",
    "            for word in words:\n",
    "                if word.isdigit():\n",
    "                    numbers.append(int(word))\n",
    "                elif word in ['+', '-', '*', '/']:\n",
    "                    operation = word\n",
    "            \n",
    "            if len(numbers) == 2 and operation:\n",
    "                if operation == '+':\n",
    "                    result = numbers[0] + numbers[1]\n",
    "                elif operation == '-':\n",
    "                    result = numbers[0] - numbers[1]\n",
    "                elif operation == '*':\n",
    "                    result = numbers[0] * numbers[1]\n",
    "                elif operation == '/':\n",
    "                    if numbers[1] != 0:\n",
    "                        result = numbers[0] / numbers[1]\n",
    "                    else:\n",
    "                        return \"I can't divide by zero!\"\n",
    "                \n",
    "                return f\"{numbers[0]} {operation} {numbers[1]} equals {result}\"\n",
    "            else:\n",
    "                return \"I need two numbers and an operation to calculate.\"\n",
    "                \n",
    "        except:\n",
    "            return \"I couldn't understand that math problem.\"\n",
    "    \n",
    "    def process_command(self, command):\n",
    "        \"\"\"Process user command and generate response with AI integration\"\"\"\n",
    "        command = command.lower().strip()\n",
    "        \n",
    "        # Try AI for complex or conversational queries first\n",
    "        if self.openai_client:\n",
    "            # Use AI for these types of queries\n",
    "            ai_triggers = [\n",
    "                'how are you', 'tell me a story', 'what do you think', 'explain', 'why', \n",
    "                'how does', 'can you', 'do you', 'what would', 'i feel', 'i think',\n",
    "                'opinion', 'advice', 'recommend', 'suggest', 'weather', 'founded',\n",
    "                'who founded', 'how to', 'what happened', 'when did'\n",
    "            ]\n",
    "            \n",
    "            # Use AI if query is long or contains AI trigger words\n",
    "            use_ai = (len(command.split()) > 6 or \n",
    "                     any(trigger in command for trigger in ai_triggers) or\n",
    "                     command.endswith('?') or\n",
    "                     '?' in command)\n",
    "            \n",
    "            if use_ai:\n",
    "                print(\"ğŸ§  Using AI for intelligent response...\")\n",
    "                ai_response = self.get_ai_response(command)\n",
    "                if ai_response:\n",
    "                    return ai_response\n",
    "        \n",
    "        # Basic command processing (fast responses)\n",
    "        if any(word in command for word in ['hello', 'hi', 'hey', 'good morning', 'good afternoon']):\n",
    "            return random.choice(self.responses['greetings'])\n",
    "        \n",
    "        elif any(word in command for word in ['goodbye', 'bye', 'see you', 'farewell']):\n",
    "            return random.choice(self.responses['farewell'])\n",
    "        \n",
    "        elif any(word in command for word in ['thank', 'thanks', 'appreciate']):\n",
    "            return random.choice(self.responses['thanks'])\n",
    "        \n",
    "        elif 'time' in command:\n",
    "            return self.get_current_time()\n",
    "        \n",
    "        elif 'date' in command or 'today' in command:\n",
    "            return self.get_current_date()\n",
    "        \n",
    "        elif any(word in command for word in ['plus', 'minus', 'times', 'divided', 'add', 'subtract', 'multiply', 'divide']) and any(char.isdigit() for char in command):\n",
    "            return self.simple_math(command)\n",
    "        \n",
    "        elif any(phrase in command for phrase in ['tell me about', 'what is', 'who is', 'search for']):\n",
    "            return self.search_wikipedia(command)\n",
    "        \n",
    "        elif 'your name' in command or 'who are you' in command:\n",
    "            return f\"I'm {self.name}, your personal voice agent! I can help you with time, dates, simple math, and general information.\"\n",
    "        \n",
    "        elif 'help' in command or 'what can you do' in command:\n",
    "            return \"I can tell you the time and date, do simple math, search for information, and have conversations with you! Try asking me anything!\"\n",
    "        \n",
    "        else:\n",
    "            return random.choice(self.responses['unknown'])\n",
    "\n",
    "# Create agents for different purposes\n",
    "agent = VoiceAgent(\"Sophia\", enable_tts=False)  # For testing in Jupyter\n",
    "agent_with_voice = VoiceAgent(\"Sophia\", enable_tts=True)  # For real conversations\n",
    "\n",
    "# Test function\n",
    "def test_voice_agent():\n",
    "    \"\"\"Test the voice agent with sample commands (text-only for Jupyter)\"\"\"\n",
    "    print(\"ğŸ§ª TESTING OUR VOICE AGENT (Text-Only Mode)\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    test_commands = [\n",
    "        \"hello\",\n",
    "        \"what time is it\",\n",
    "        \"what is today's date\",\n",
    "        \"what is 15 plus 27\",\n",
    "        \"tell me about artificial intelligence\",\n",
    "        \"what can you do\",\n",
    "        \"how are you feeling today\",  # This should trigger AI\n",
    "        \"thank you\",\n",
    "        \"goodbye\"\n",
    "    ]\n",
    "    \n",
    "    for i, command in enumerate(test_commands, 1):\n",
    "        print(f\"\\nğŸ”¬ Test {i}: '{command}'\")\n",
    "        response = agent.process_command(command)\n",
    "        agent.speak(response)\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "# Voice conversation function\n",
    "def start_voice_conversation():\n",
    "    \"\"\"Start a real voice conversation with TTS enabled\"\"\"\n",
    "    print(\"ğŸ‰ Starting Voice Conversation with TTS!\")\n",
    "    print(\"Say 'goodbye' to end the conversation.\")\n",
    "    \n",
    "    agent_with_voice.speak(\"Hello! I'm ready to have a conversation with you!\")\n",
    "    \n",
    "    conversation_count = 0\n",
    "    max_conversations = 10\n",
    "    \n",
    "    while conversation_count < max_conversations:\n",
    "        user_input = agent_with_voice.listen()\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "            \n",
    "        if any(word in user_input for word in ['goodbye', 'bye', 'exit', 'quit']):\n",
    "            agent_with_voice.speak(\"Goodbye! It was great talking with you!\")\n",
    "            break\n",
    "        \n",
    "        response = agent_with_voice.process_command(user_input)\n",
    "        agent_with_voice.speak(response)\n",
    "        \n",
    "        conversation_count += 1\n",
    "        print(f\"ğŸ’¬ Conversation {conversation_count}/{max_conversations}\")\n",
    "        print(\"-\" * 30)\n",
    "    \n",
    "    if conversation_count >= max_conversations:\n",
    "        agent_with_voice.speak(\"We've had such a wonderful conversation! Let's chat again soon!\")\n",
    "    \n",
    "    print(\"\\nâœ… Conversation ended!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ® Step 5: Testing Our Voice Agent\n",
    " \n",
    " Let's test our voice agent with different types of commands!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ Starting Voice Conversation with TTS!\n",
      "Say 'goodbye' to end the conversation.\n",
      "ğŸ¤– Sophia: Hello! I'm ready to have a conversation with you!\n",
      "ğŸ§ Listening...\n",
      "ğŸ”„ Processing...\n",
      "ğŸ‘¤ You said: 'hello'\n",
      "ğŸ¤– Sophia: Hello! I'm Sophia, your voice agent!\n",
      "ğŸ’¬ Conversation 1/10\n",
      "------------------------------\n",
      "ğŸ§ Listening...\n",
      "ğŸ”„ Processing...\n",
      "ğŸ‘¤ You said: 'so what can you do tell me'\n",
      "ğŸ§  Using AI for intelligent response...\n",
      "ğŸ¤– Sophia: I can help you with information, reminders, setting timers, and answering questions. Just let me know what you need!\n",
      "ğŸ’¬ Conversation 2/10\n",
      "------------------------------\n",
      "ğŸ§ Listening...\n",
      "ğŸ”„ Processing...\n",
      "ğŸ‘¤ You said: 'please set a reminder'\n",
      "ğŸ¤– Sophia: That's interesting! I don't know about that yet.\n",
      "ğŸ’¬ Conversation 3/10\n",
      "------------------------------\n",
      "ğŸ§ Listening...\n",
      "ğŸ”„ Processing...\n",
      "ğŸ‘¤ You said: 'please set a reminder'\n",
      "ğŸ¤– Sophia: That's interesting! I don't know about that yet.\n",
      "ğŸ’¬ Conversation 4/10\n",
      "------------------------------\n",
      "ğŸ§ Listening...\n",
      "ğŸ”„ Processing...\n",
      "ğŸ‘¤ You said: 'can you tell me the'\n",
      "ğŸ§  Using AI for intelligent response...\n",
      "ğŸ¤– Sophia: It looks like your question got cut off! What would you like to know?\n",
      "ğŸ’¬ Conversation 5/10\n",
      "------------------------------\n",
      "ğŸ§ Listening...\n",
      "ğŸ”„ Processing...\n",
      "ğŸ‘¤ You said: 'tell me the weather today'\n",
      "ğŸ§  Using AI for intelligent response...\n",
      "ğŸ¤– Sophia: I can't check real-time weather, but you can easily find it on a weather app or website. Would you like tips on how to stay prepared for the weather?\n",
      "ğŸ’¬ Conversation 6/10\n",
      "------------------------------\n",
      "ğŸ§ Listening...\n",
      "ğŸ”„ Processing...\n",
      "ğŸ‘¤ You said: 'yes please'\n",
      "ğŸ¤– Sophia: I'm not sure about that. Can you teach me?\n",
      "ğŸ’¬ Conversation 7/10\n",
      "------------------------------\n",
      "ğŸ§ Listening...\n",
      "ğŸ”„ Processing...\n",
      "ğŸ‘¤ You said: 'that means please tell me the further'\n",
      "ğŸ§  Using AI for intelligent response...\n",
      "ğŸ¤– Sophia: Could you clarify what youâ€™d like to know more about? I'm here to help!\n",
      "ğŸ’¬ Conversation 8/10\n",
      "------------------------------\n",
      "ğŸ§ Listening...\n",
      "ğŸ”„ Processing...\n",
      "ğŸ‘¤ You said: 'okay anime'\n",
      "ğŸ¤– Sophia: That's interesting! I don't know about that yet.\n",
      "ğŸ’¬ Conversation 9/10\n",
      "------------------------------\n",
      "ğŸ§ Listening...\n",
      "ğŸ”„ Processing...\n",
      "ğŸ‘¤ You said: 'how are you today'\n",
      "ğŸ§  Using AI for intelligent response...\n",
      "ğŸ¤– Sophia: I'm doing great, thank you! How about you?\n",
      "ğŸ’¬ Conversation 10/10\n",
      "------------------------------\n",
      "ğŸ¤– Sophia: We've had such a wonderful conversation! Let's chat again soon!\n",
      "\n",
      "âœ… Conversation ended!\n"
     ]
    }
   ],
   "source": [
    "# test_voice_agent()\n",
    "\n",
    "start_voice_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Step 6: Your Turn - Customize Your Agent!\n",
    " \n",
    "Now it's time to make your voice agent unique! Try these customizations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Searching for US female voices...\n",
      "ğŸ­ Selected US female voice: Samantha\n",
      "âœ… GPT-4o-mini connected successfully from .env file!\n",
      "ğŸ¤– YourNameHere is ready to help with voice enabled!\n",
      "ğŸ¨ Your agent has been customized!\n",
      "Try asking your agent:\n",
      "- 'Tell me a joke'\n",
      "- 'What's your favorite color?'\n",
      "- 'Tell me about yourself'\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¨ CUSTOMIZATION PLAYGROUND\n",
    "# ===========================\n",
    "\n",
    "# 1. Change your agent's name\n",
    "my_agent = VoiceAgent(\"YourNameHere\")  # Change this!\n",
    "\n",
    "# 2. Add new responses\n",
    "def add_custom_responses():\n",
    "    \"\"\"Add your own custom responses\"\"\"\n",
    "    \n",
    "    # Add jokes\n",
    "    jokes = [\n",
    "        \"Why don't scientists trust atoms? Because they make up everything!\",\n",
    "        \"What do you call a bear with no teeth? A gummy bear!\",\n",
    "        \"Why did the math book look so sad? Because it had too many problems!\"\n",
    "    ]\n",
    "    \n",
    "    # Add facts about yourself\n",
    "    personal_facts = [\n",
    "        \"I was created by an awesome Class 9 student!\",\n",
    "        \"I love learning new things every day!\",\n",
    "        \"My favorite subject is computer science!\"\n",
    "    ]\n",
    "    \n",
    "    my_agent.responses['jokes'] = jokes\n",
    "    my_agent.responses['personal'] = personal_facts\n",
    "\n",
    "# 3. Add new functionality\n",
    "def enhanced_process_command(self, command):\n",
    "    \"\"\"Enhanced command processing with new features\"\"\"\n",
    "    command = command.lower().strip()\n",
    "    \n",
    "    # Original processing\n",
    "    original_response = VoiceAgent.process_command(self, command)\n",
    "    \n",
    "    # New features\n",
    "    if 'joke' in command or 'funny' in command:\n",
    "        return random.choice(self.responses.get('jokes', ['I need to learn some jokes!']))\n",
    "    \n",
    "    elif 'about you' in command or 'about yourself' in command:\n",
    "        return random.choice(self.responses.get('personal', ['I am a voice agent!']))\n",
    "    \n",
    "    elif 'weather' in command:\n",
    "        return \"I don't have access to weather data yet, but you could add that feature!\"\n",
    "    \n",
    "    elif 'favorite' in command:\n",
    "        favorites = [\n",
    "            \"My favorite programming language is Python!\",\n",
    "            \"I love helping students learn about technology!\",\n",
    "            \"My favorite time is when I'm talking with you!\"\n",
    "        ]\n",
    "        return random.choice(favorites)\n",
    "    \n",
    "    else:\n",
    "        return original_response\n",
    "\n",
    "# Apply customizations\n",
    "add_custom_responses()\n",
    "# Replace the method (advanced Python technique)\n",
    "VoiceAgent.process_command = enhanced_process_command\n",
    "\n",
    "print(\"ğŸ¨ Your agent has been customized!\")\n",
    "print(\"Try asking your agent:\")\n",
    "print(\"- 'Tell me a joke'\")\n",
    "print(\"- 'What's your favorite color?'\")\n",
    "print(\"- 'Tell me about yourself'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ† Step 7: Final Challenge - Build Your Feature!\n",
    " \n",
    "Time for the ultimate challenge! Add your own unique feature to the voice agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒŸ Your custom feature: Motivational Quotes\n",
      "Here's some motivation for you: Technology is best when it brings people together!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ YOUR CHALLENGE: Add a new feature!\n",
    "# ====================================\n",
    "\n",
    "def your_custom_feature():\n",
    "    \"\"\"\n",
    "    YOUR TURN: Create a unique feature for your voice agent!\n",
    "    \n",
    "    Ideas:\n",
    "    1. Password generator\n",
    "    2. Random compliment generator\n",
    "    3. Study reminder system\n",
    "    4. Simple game (like 20 questions)\n",
    "    5. Unit converter (inches to cm, etc.)\n",
    "    6. Random fact generator\n",
    "    7. Motivational quotes\n",
    "    \n",
    "    Fill in this function with your code!\n",
    "    \"\"\"\n",
    "    \n",
    "    # Example: Random motivational quotes\n",
    "    motivational_quotes = [\n",
    "        \"The future belongs to those who learn more skills and combine them in creative ways!\",\n",
    "        \"Every expert was once a beginner. Keep learning!\",\n",
    "        \"Technology is best when it brings people together!\",\n",
    "        \"The only way to do great work is to love what you do!\",\n",
    "        \"Innovation distinguishes between a leader and a follower!\"\n",
    "    ]\n",
    "    \n",
    "    # Your code here!\n",
    "    feature_name = \"Motivational Quotes\"  # Change this\n",
    "    \n",
    "    print(f\"ğŸŒŸ Your custom feature: {feature_name}\")\n",
    "    \n",
    "    # Example implementation\n",
    "    quote = random.choice(motivational_quotes)\n",
    "    return f\"Here's some motivation for you: {quote}\"\n",
    "\n",
    "# Test your feature\n",
    "my_feature_result = your_custom_feature()\n",
    "print(my_feature_result)\n",
    "\n",
    "# Now integrate it into your agent by modifying the process_command function!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 10: Understanding How It All Works\n",
    " \n",
    "Let's recap what we've built and understand the technology behind it!\n",
    "\n",
    "### ğŸ”¬ UNDERSTANDING VOICE AGENT TECHNOLOGY\n",
    "==================================================\n",
    "\n",
    "ğŸ”§ Speech Recognition (ASR)\n",
    "------------------------\n",
    "ğŸ“ Converts your speech into text that computers can understand\n",
    "\n",
    "ğŸ”„ Process:\n",
    "   1. Microphone captures sound waves from your voice\n",
    "   2. Audio is converted to digital format\n",
    "   3. AI models analyze patterns in the audio\n",
    "   4. System matches patterns to known words\n",
    "   5. Returns the most likely text transcription\n",
    "\n",
    "ğŸŒ Real-world applications: Used in Siri, Google Assistant, Alexa, voice typing\n",
    "\n",
    "\n",
    "ğŸ”§ Text-to-Speech (TTS)\n",
    "--------------------\n",
    "ğŸ“ Converts text into natural-sounding speech\n",
    "\n",
    "ğŸ”„ Process:\n",
    "   1. System analyzes the text for meaning and grammar\n",
    "   2. Determines correct pronunciation for each word\n",
    "   3. Applies natural rhythm and intonation\n",
    "   4. Generates audio waveforms\n",
    "   5. Plays the speech through speakers\n",
    "\n",
    "ğŸŒ Real-world applications: GPS navigation, accessibility tools, audiobooks, virtual assistants\n",
    "\n",
    "\n",
    "ğŸ”§ Natural Language Processing\n",
    "---------------------------\n",
    "ğŸ“ Helps computers understand the meaning behind words\n",
    "\n",
    "ğŸ”„ Process:\n",
    "   1. Breaks down sentences into individual words\n",
    "   2. Identifies the intent (what user wants)\n",
    "   3. Extracts key information (entities)\n",
    "   4. Determines appropriate response\n",
    "   5. Generates helpful output\n",
    "\n",
    "ğŸŒ Real-world applications: Chatbots, language translation, sentiment analysis\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w9-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
